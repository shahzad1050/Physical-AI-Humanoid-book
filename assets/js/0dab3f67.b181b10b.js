"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[1472],{5870:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module4/manipulation","title":"Manipulation and Grasping","description":"Introduction to Humanoid Manipulation","source":"@site/docs/module4/manipulation.md","sourceDirName":"module4","slug":"/module4/manipulation","permalink":"/Physical-AI-Humanoid-book/docs/module4/manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/user/physical-ai-humanoid-robotics/tree/main/docs/module4/manipulation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Practical Lab: Building a Humanoid Robot Controller","permalink":"/Physical-AI-Humanoid-book/docs/module4/lab-humanoid-controller"},"next":{"title":"Glossary of Terms: Physical AI & Humanoid Robotics","permalink":"/Physical-AI-Humanoid-book/docs/glossary"}}');var o=t(4848),a=t(8453);const s={},r="Manipulation and Grasping",l={},c=[{value:"Introduction to Humanoid Manipulation",id:"introduction-to-humanoid-manipulation",level:2},{value:"Humanoid Manipulation Challenges",id:"humanoid-manipulation-challenges",level:2},{value:"Balance and Stability",id:"balance-and-stability",level:3},{value:"Kinematic Redundancy",id:"kinematic-redundancy",level:3},{value:"Environmental Interaction",id:"environmental-interaction",level:3},{value:"Kinematic Considerations for Manipulation",id:"kinematic-considerations-for-manipulation",level:2},{value:"Dual-Arm Coordination",id:"dual-arm-coordination",level:3},{value:"Manipulability Optimization",id:"manipulability-optimization",level:3},{value:"Grasping Strategies",id:"grasping-strategies",level:2},{value:"Grasp Planning for Humanoid Robots",id:"grasp-planning-for-humanoid-robots",level:3},{value:"Grasp Execution and Force Control",id:"grasp-execution-and-force-control",level:3},{value:"Bimanual Manipulation",id:"bimanual-manipulation",level:2},{value:"Coordinated Two-Hand Manipulation",id:"coordinated-two-hand-manipulation",level:3},{value:"Whole-Body Manipulation",id:"whole-body-manipulation",level:2},{value:"Integration of Manipulation and Locomotion",id:"integration-of-manipulation-and-locomotion",level:3},{value:"Advanced Manipulation Techniques",id:"advanced-manipulation-techniques",level:2},{value:"Variable Impedance Control",id:"variable-impedance-control",level:3},{value:"Learning-Based Manipulation",id:"learning-based-manipulation",level:3},{value:"Simulation and Testing Framework",id:"simulation-and-testing-framework",level:2},{value:"Manipulation Testing Environment",id:"manipulation-testing-environment",level:3},{value:"Summary",id:"summary",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"manipulation-and-grasping",children:"Manipulation and Grasping"})}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-humanoid-manipulation",children:"Introduction to Humanoid Manipulation"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid manipulation refers to the ability of humanoid robots to interact with objects in their environment using their arms and hands. Unlike specialized manipulators, humanoid robots must coordinate their entire body to perform manipulation tasks while maintaining balance and stability. This introduces unique challenges and opportunities in the field of robotics."}),"\n",(0,o.jsx)(e.h2,{id:"humanoid-manipulation-challenges",children:"Humanoid Manipulation Challenges"}),"\n",(0,o.jsx)(e.h3,{id:"balance-and-stability",children:"Balance and Stability"}),"\n",(0,o.jsx)(e.p,{children:"The primary challenge in humanoid manipulation is maintaining balance while performing tasks:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Center of Mass (CoM) Management"}),": Moving arms changes the robot's CoM, potentially causing instability"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Whole-Body Coordination"}),": Arms, torso, and legs must work together during manipulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dynamic Balance"}),": Maintaining stability during dynamic manipulation tasks"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Multi-Task Optimization"}),": Balancing manipulation performance with stability requirements"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"kinematic-redundancy",children:"Kinematic Redundancy"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots typically have redundant degrees of freedom (DOF):"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Task Space Redundancy"}),": Multiple joint configurations can achieve the same end-effector pose"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Null Space Optimization"}),": Using redundancy for secondary objectives like joint limit avoidance"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Obstacle Avoidance"}),": Navigating around obstacles while maintaining balance"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Workspace Optimization"}),": Maximizing manipulability while maintaining stability"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"environmental-interaction",children:"Environmental Interaction"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots must handle various types of interactions:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Rigid Contact"}),": Grasping and manipulating solid objects"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Compliant Interaction"}),": Handling deformable objects and environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Variable Impedance"}),": Adapting to different task requirements"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Force Control"}),": Applying appropriate forces during manipulation"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"kinematic-considerations-for-manipulation",children:"Kinematic Considerations for Manipulation"}),"\n",(0,o.jsx)(e.h3,{id:"dual-arm-coordination",children:"Dual-Arm Coordination"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots typically have two arms, requiring coordination algorithms:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\nclass DualArmCoordinator:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.left_arm_chain = robot_model.get_arm_chain(\'left\')\n        self.right_arm_chain = robot_model.get_arm_chain(\'right\')\n\n    def coordinate_dual_arm_motion(self, left_target, right_target, current_joints):\n        """\n        Coordinate motion of both arms while considering balance constraints\n        """\n        # Calculate inverse kinematics for each arm separately\n        left_joints = self.inverse_kinematics_single_arm(\n            \'left\', left_target, current_joints\n        )\n        right_joints = self.inverse_kinematics_single_arm(\n            \'right\', right_target, current_joints\n        )\n\n        # Check for joint limit conflicts and collisions\n        if self.check_joint_limit_conflict(left_joints, right_joints):\n            # Resolve conflict using optimization\n            left_joints, right_joints = self.resolve_joint_conflict(\n                left_joints, right_joints, left_target, right_target\n            )\n\n        # Verify whole-body configuration maintains balance\n        if not self.verify_balance_constraint(left_joints, right_joints):\n            # Adjust arm positions to maintain balance\n            left_joints, right_joints = self.adjust_for_balance(\n                left_joints, right_joints, current_joints\n            )\n\n        return np.concatenate([left_joints, right_joints])\n\n    def inverse_kinematics_single_arm(self, arm_side, target_pose, current_joints):\n        """\n        Calculate inverse kinematics for a single arm\n        """\n        if arm_side == \'left\':\n            arm_chain = self.left_arm_chain\n            joint_indices = self.model.left_arm_joint_indices\n        else:\n            arm_chain = self.right_arm_chain\n            joint_indices = self.model.right_arm_joint_indices\n\n        # Extract current arm joint positions\n        current_arm_joints = current_joints[joint_indices]\n\n        # Solve inverse kinematics (using analytical or numerical method)\n        target_position = target_pose[:3, 3]\n        target_orientation = target_pose[:3, :3]\n\n        # Simplified approach - in practice, use specialized IK solvers\n        new_joints = self.solve_arm_ik(\n            arm_chain, target_position, target_orientation, current_arm_joints\n        )\n\n        return new_joints\n\n    def solve_arm_ik(self, arm_chain, target_pos, target_rot, current_joints):\n        """\n        Solve inverse kinematics for arm (simplified implementation)\n        """\n        # This would typically use:\n        # - Analytical solutions for simple chains\n        # - Numerical methods (Jacobian-based) for complex chains\n        # - Optimization-based approaches for redundant chains\n\n        # For this example, return current joints (placeholder)\n        return current_joints\n\n    def check_joint_limit_conflict(self, left_joints, right_joints):\n        """\n        Check if joint configurations conflict with each other\n        """\n        # Check if arms collide with each other or with body\n        left_limits = self.model.get_joint_limits(\'left_arm\')\n        right_limits = self.model.get_joint_limits(\'right_arm\')\n\n        # Check joint limits\n        for i, (left_joint, (min_limit, max_limit)) in enumerate(zip(left_joints, left_limits)):\n            if left_joint < min_limit or left_joint > max_limit:\n                return True\n\n        for i, (right_joint, (min_limit, max_limit)) in enumerate(zip(right_joints, right_limits)):\n            if right_joint < min_limit or right_joint > max_limit:\n                return True\n\n        # Check for inter-arm collisions (simplified)\n        left_elbow_pos = self.calculate_elbow_position(\'left\', left_joints)\n        right_elbow_pos = self.calculate_elbow_position(\'right\', right_joints)\n\n        if np.linalg.norm(left_elbow_pos - right_elbow_pos) < 0.1:  # 10cm threshold\n            return True\n\n        return False\n\n    def resolve_joint_conflict(self, left_joints, right_joints, left_target, right_target):\n        """\n        Resolve conflicts between left and right arm configurations\n        """\n        # Use optimization to find configuration that minimizes conflict\n        # while staying close to desired targets\n\n        # Simplified approach: adjust joints slightly to avoid conflicts\n        adjusted_left = left_joints.copy()\n        adjusted_right = right_joints.copy()\n\n        # Move arms slightly apart if they\'re too close\n        left_elbow = self.calculate_elbow_position(\'left\', adjusted_left)\n        right_elbow = self.calculate_elbow_position(\'right\', adjusted_right)\n\n        distance = np.linalg.norm(left_elbow - right_elbow)\n        if distance < 0.1:  # Too close\n            # Move left arm slightly left, right arm slightly right\n            direction = (right_elbow - left_elbow) / distance\n            adjustment = 0.05 * direction  # 5cm adjustment\n\n            adjusted_left = self.adjust_arm_position(\'left\', adjusted_left, adjustment)\n            adjusted_right = self.adjust_arm_position(\'right\', adjusted_right, -adjustment)\n\n        return adjusted_left, adjusted_right\n\n    def verify_balance_constraint(self, left_joints, right_joints):\n        """\n        Verify that arm configuration maintains robot balance\n        """\n        # Calculate CoM with new arm positions\n        all_joints = self.combine_arm_joints(left_joints, right_joints)\n\n        com_pos = self.model.calculate_com_position(all_joints)\n        zmp_pos = self.model.calculate_zmp(all_joints)\n\n        # Check if ZMP is within support polygon\n        support_polygon = self.model.calculate_support_polygon()\n        return self.is_zmp_stable(zmp_pos, support_polygon)\n\n    def adjust_for_balance(self, left_joints, right_joints, current_joints):\n        """\n        Adjust arm positions to maintain balance\n        """\n        # Calculate how arm positions affect CoM\n        original_com = self.model.calculate_com_position(current_joints)\n        new_joints = self.combine_arm_joints(left_joints, right_joints)\n        new_com = self.model.calculate_com_position(new_joints)\n\n        # Calculate CoM displacement\n        com_displacement = new_com - original_com\n\n        # Adjust to move CoM back toward stable region\n        # This is a simplified approach - full implementation would be more complex\n        adjustment_factor = 0.5  # Partial adjustment\n\n        adjusted_left = left_joints - adjustment_factor * com_displacement[:len(left_joints)]\n        adjusted_right = right_joints - adjustment_factor * com_displacement[:len(right_joints)]\n\n        return adjusted_left, adjusted_right\n\n    def calculate_elbow_position(self, arm_side, joints):\n        """\n        Calculate elbow position given joint angles (simplified)\n        """\n        # This would use forward kinematics\n        # Simplified as an example\n        if arm_side == \'left\':\n            return np.array([0.2, 0.2, 1.2])  # Placeholder\n        else:\n            return np.array([0.2, -0.2, 1.2])  # Placeholder\n\n    def adjust_arm_position(self, arm_side, current_joints, adjustment):\n        """\n        Adjust arm joint positions by given displacement\n        """\n        # Simplified adjustment\n        adjusted = current_joints.copy()\n        # Apply adjustment to relevant joints\n        return adjusted\n\n    def combine_arm_joints(self, left_joints, right_joints):\n        """\n        Combine left and right arm joints into full body configuration\n        """\n        # This would combine with torso and leg joints\n        return np.concatenate([left_joints, right_joints])\n'})}),"\n",(0,o.jsx)(e.h3,{id:"manipulability-optimization",children:"Manipulability Optimization"}),"\n",(0,o.jsx)(e.p,{children:"Maximizing the robot's ability to manipulate objects effectively:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class ManipulabilityOptimizer:\n    def __init__(self, robot_model):\n        self.model = robot_model\n\n    def calculate_manipulability_index(self, joint_angles, task_jacobian):\n        """\n        Calculate manipulability index for a given configuration\n        """\n        # Manipulability index: w = sqrt(det(J * J^T))\n        # For redundant systems, often use: w = sqrt(product of non-zero singular values)\n        J = task_jacobian\n        JJT = J @ J.T\n        manipulability = np.sqrt(np.linalg.det(JJT)) if JJT.shape[0] == JJT.shape[1] else 0\n\n        if manipulability == 0:\n            # For redundant systems, use singular values\n            U, s, Vh = np.linalg.svd(J)\n            manipulability = np.prod(s[s > 1e-6])  # Product of non-zero singular values\n\n        return manipulability\n\n    def optimize_manipulability(self, target_pose, current_config, constraints=None):\n        """\n        Optimize joint configuration for maximum manipulability\n        """\n        from scipy.optimize import minimize\n\n        def objective(joint_vars):\n            # Calculate manipulability for this configuration\n            jacobian = self.model.calculate_jacobian(target_pose, joint_vars)\n            manip_idx = self.calculate_manipulability_index(joint_vars, jacobian)\n            return -manip_idx  # Negative because we minimize\n\n        # Define constraints\n        bounds = self.model.get_joint_limits()\n\n        # Add balance constraint if needed\n        if constraints and \'balance\' in constraints:\n            # Add balance constraint function\n            pass\n\n        # Optimize\n        result = minimize(\n            objective,\n            current_config,\n            method=\'SLSQP\',\n            bounds=bounds,\n            constraints=constraints\n        )\n\n        return result.x if result.success else current_config\n\n    def calculate_task_jacobian(self, joint_angles, task_frame=\'end_effector\'):\n        """\n        Calculate task space Jacobian for manipulation tasks\n        """\n        # This would compute the relationship between joint velocities\n        # and task space velocities\n        n_joints = len(joint_angles)\n        if task_frame == \'end_effector\':\n            task_dim = 6  # Position (3) + Orientation (3)\n        else:\n            task_dim = 3  # Position only\n\n        jacobian = np.zeros((task_dim, n_joints))\n\n        # Calculate Jacobian columns for each joint\n        for i in range(n_joints):\n            # Get joint axis and position in task frame\n            joint_axis = self.model.get_joint_axis(i, joint_angles)\n            joint_pos = self.model.get_joint_position(i, joint_angles)\n            ee_pos = self.model.get_end_effector_position(joint_angles)\n\n            if task_frame == \'end_effector\':\n                # Linear velocity part\n                r = ee_pos - joint_pos\n                jacobian[:3, i] = np.cross(joint_axis, r)\n                # Angular velocity part\n                jacobian[3:6, i] = joint_axis\n            else:\n                # Position only\n                r = ee_pos - joint_pos\n                jacobian[:, i] = np.cross(joint_axis, r)\n\n        return jacobian\n'})}),"\n",(0,o.jsx)(e.h2,{id:"grasping-strategies",children:"Grasping Strategies"}),"\n",(0,o.jsx)(e.h3,{id:"grasp-planning-for-humanoid-robots",children:"Grasp Planning for Humanoid Robots"}),"\n",(0,o.jsx)(e.p,{children:"Grasp planning for humanoid robots must consider the entire body configuration:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class HumanoidGraspPlanner:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.hand_model = robot_model.hand_model\n        self.kinematics = robot_model.kinematics\n\n    def plan_grasp(self, object_info, current_state):\n        \"\"\"\n        Plan a grasp considering whole-body configuration\n        \"\"\"\n        # 1. Analyze object properties\n        object_pose = object_info['pose']\n        object_dims = object_info['dimensions']\n        object_weight = object_info['weight']\n        object_surface = object_info['surface_properties']\n\n        # 2. Generate grasp candidates\n        grasp_candidates = self.generate_grasp_candidates(\n            object_info, current_state\n        )\n\n        # 3. Evaluate candidates considering:\n        # - Hand reachability\n        # - Whole-body balance\n        # - Grasp stability\n        # - Task requirements\n\n        evaluated_candidates = []\n        for grasp in grasp_candidates:\n            score = self.evaluate_grasp_candidate(\n                grasp, object_info, current_state\n            )\n            evaluated_candidates.append((grasp, score))\n\n        # 4. Select best grasp\n        best_grasp = max(evaluated_candidates, key=lambda x: x[1])[0]\n\n        return best_grasp\n\n    def generate_grasp_candidates(self, object_info, current_state):\n        \"\"\"\n        Generate potential grasp configurations\n        \"\"\"\n        object_pose = object_info['pose']\n        object_dims = object_info['dimensions']\n\n        candidates = []\n\n        # Generate top grasp\n        top_grasp = self.generate_top_grasp(object_pose, object_dims)\n        candidates.append(top_grasp)\n\n        # Generate side grasps\n        side_grasps = self.generate_side_grasps(object_pose, object_dims)\n        candidates.extend(side_grasps)\n\n        # Generate precision grasps\n        precision_grasps = self.generate_precision_grasps(object_pose, object_dims)\n        candidates.extend(precision_grasps)\n\n        # Generate power grasps\n        power_grasps = self.generate_power_grasps(object_pose, object_dims)\n        candidates.extend(power_grasps)\n\n        return candidates\n\n    def generate_top_grasp(self, object_pose, object_dims):\n        \"\"\"\n        Generate a top-down grasp\n        \"\"\"\n        # Position hand above object\n        grasp_pose = object_pose.copy()\n        grasp_pose[2, 3] += object_dims[2] / 2 + 0.05  # 5cm above object\n\n        # Orient hand for top grasp\n        # This would involve complex hand pose calculations\n        return {\n            'pose': grasp_pose,\n            'type': 'top',\n            'approach_direction': np.array([0, 0, -1]),  # Approach from above\n            'grasp_width': min(object_dims[0], object_dims[1]) * 0.8  # 80% of smaller dimension\n        }\n\n    def generate_side_grasps(self, object_pose, object_dims):\n        \"\"\"\n        Generate side grasps from different directions\n        \"\"\"\n        side_grasps = []\n\n        # Generate grasps from 4 sides\n        for angle in [0, np.pi/2, np.pi, 3*np.pi/2]:\n            grasp_pose = object_pose.copy()\n            # Move to side of object\n            grasp_pose[0, 3] += np.cos(angle) * (object_dims[0] / 2 + 0.02)\n            grasp_pose[1, 3] += np.sin(angle) * (object_dims[1] / 2 + 0.02)\n\n            # Orient hand for side grasp\n            side_grasps.append({\n                'pose': grasp_pose,\n                'type': 'side',\n                'approach_direction': np.array([-np.cos(angle), -np.sin(angle), 0]),\n                'grasp_width': object_dims[2] * 0.8  # Height of object\n            })\n\n        return side_grasps\n\n    def generate_precision_grasps(self, object_pose, object_dims):\n        \"\"\"\n        Generate precision grasp configurations\n        \"\"\"\n        # For small objects, generate pinch or precision grasps\n        if max(object_dims) < 0.1:  # Less than 10cm\n            grasp_pose = object_pose.copy()\n            # Position for precision grasp\n            return [{\n                'pose': grasp_pose,\n                'type': 'precision',\n                'approach_direction': np.array([0, 0, -1]),\n                'grasp_width': min(object_dims) * 0.6\n            }]\n        return []\n\n    def generate_power_grasps(self, object_pose, object_dims):\n        \"\"\"\n        Generate power grasp configurations\n        \"\"\"\n        # For larger objects, generate power grasps\n        if max(object_dims) > 0.15:  # Greater than 15cm\n            grasp_pose = object_pose.copy()\n            # Position for power grasp\n            return [{\n                'pose': grasp_pose,\n                'type': 'power',\n                'approach_direction': np.array([0, 0, -1]),\n                'grasp_width': max(object_dims) * 0.7\n            }]\n        return []\n\n    def evaluate_grasp_candidate(self, grasp, object_info, current_state):\n        \"\"\"\n        Evaluate a grasp candidate considering multiple factors\n        \"\"\"\n        score = 0.0\n\n        # 1. Reachability score (can the hand reach the grasp pose?)\n        reachability_score = self.evaluate_reachability(grasp, current_state)\n        score += 0.3 * reachability_score\n\n        # 2. Balance score (does the grasp maintain stability?)\n        balance_score = self.evaluate_balance_impact(grasp, current_state)\n        score += 0.25 * balance_score\n\n        # 3. Grasp stability score\n        stability_score = self.evaluate_grasp_stability(grasp, object_info)\n        score += 0.25 * stability_score\n\n        # 4. Task appropriateness score\n        task_score = self.evaluate_task_appropriateness(grasp, object_info)\n        score += 0.2 * task_score\n\n        return score\n\n    def evaluate_reachability(self, grasp, current_state):\n        \"\"\"\n        Evaluate if the grasp pose is reachable\n        \"\"\"\n        # Check if the target pose is within the arm's workspace\n        target_pose = grasp['pose']\n        current_joints = current_state['joint_positions']\n\n        # Try to solve inverse kinematics\n        ik_solution = self.kinematics.inverse_kinematics(\n            target_pose, current_joints\n        )\n\n        if ik_solution is not None:\n            # Check for joint limit violations\n            joint_limits = self.model.get_joint_limits()\n            violations = 0\n            for i, (joint_val, (min_lim, max_lim)) in enumerate(zip(ik_solution, joint_limits)):\n                if joint_val < min_lim or joint_val > max_lim:\n                    violations += 1\n\n            if violations == 0:\n                return 1.0  # Fully reachable\n            else:\n                return max(0.0, 1.0 - violations * 0.1)  # Reduce score for each violation\n        else:\n            return 0.0  # Not reachable\n\n    def evaluate_balance_impact(self, grasp, current_state):\n        \"\"\"\n        Evaluate the impact of the grasp on robot balance\n        \"\"\"\n        # Calculate CoM with hand at grasp position\n        current_com = current_state['com_position']\n        hand_position = grasp['pose'][:3, 3]\n\n        # Estimate CoM shift due to arm extension\n        arm_mass = 2.0  # Estimated arm mass\n        robot_mass = 70.0  # Total robot mass\n        estimated_com_shift = (hand_position - current_com) * (arm_mass / robot_mass)\n\n        new_com = current_com + estimated_com_shift\n\n        # Check if new CoM is within support polygon\n        support_polygon = current_state['support_polygon']\n        if self.is_com_stable(new_com, support_polygon):\n            return 1.0\n        else:\n            # Calculate how much outside the polygon the CoM is\n            distance = self.distance_to_polygon(new_com[:2], support_polygon)\n            return max(0.0, 1.0 - distance * 2)  # Heuristic scaling\n\n    def evaluate_grasp_stability(self, grasp, object_info):\n        \"\"\"\n        Evaluate the stability of the grasp\n        \"\"\"\n        # Consider:\n        # - Contact points between hand and object\n        # - Friction coefficients\n        # - Object weight and center of mass\n        # - Grasp type (power vs precision)\n\n        object_weight = object_info['weight']\n        grasp_type = grasp['type']\n\n        # Basic stability evaluation\n        if grasp_type == 'power':\n            stability_factor = 0.9  # Power grasps are generally stable\n        elif grasp_type == 'precision':\n            stability_factor = 0.6  # Precision grasps less stable for heavy objects\n        else:\n            stability_factor = 0.75\n\n        # Reduce stability for heavy objects\n        if object_weight > 1.0:  # More than 1kg\n            stability_factor *= (1.0 / object_weight) ** 0.5\n\n        return stability_factor\n\n    def evaluate_task_appropriateness(self, grasp, object_info):\n        \"\"\"\n        Evaluate if the grasp is appropriate for the task\n        \"\"\"\n        # Consider object properties and intended use\n        object_shape = object_info.get('shape', 'unknown')\n        object_material = object_info.get('material', 'rigid')\n\n        grasp_type = grasp['type']\n\n        # Heuristic evaluation\n        if object_shape == 'cylindrical' and grasp_type in ['side', 'power']:\n            return 0.9  # Good match\n        elif object_shape == 'rectangular' and grasp_type in ['top', 'side']:\n            return 0.8\n        elif object_shape == 'small' and grasp_type == 'precision':\n            return 0.95\n        else:\n            return 0.5  # Neutral score\n\n    def is_com_stable(self, com_pos, support_polygon):\n        \"\"\"\n        Check if CoM is within support polygon\n        \"\"\"\n        # Simplified check for rectangular support polygon\n        return (support_polygon['min_x'] <= com_pos[0] <= support_polygon['max_x'] and\n                support_polygon['min_y'] <= com_pos[1] <= support_polygon['max_y'])\n\n    def distance_to_polygon(self, point, polygon):\n        \"\"\"\n        Calculate distance from point to polygon boundary\n        \"\"\"\n        # Simplified for rectangular polygon\n        dx = max(0, abs(point[0] - (polygon['min_x'] + polygon['max_x'])/2) - (polygon['max_x'] - polygon['min_x'])/2)\n        dy = max(0, abs(point[1] - (polygon['min_y'] + polygon['max_y'])/2) - (polygon['max_y'] - polygon['min_y'])/2)\n        return np.sqrt(dx**2 + dy**2)\n"})}),"\n",(0,o.jsx)(e.h3,{id:"grasp-execution-and-force-control",children:"Grasp Execution and Force Control"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class GraspController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.contact_model = self.initialize_contact_model()\n\n    def execute_grasp(self, grasp_plan, object_info):\n        """\n        Execute a planned grasp with appropriate force control\n        """\n        # 1. Approach phase - move to pre-grasp position\n        pre_grasp_pose = self.calculate_pre_grasp_pose(grasp_plan)\n        approach_success = self.move_to_approach_pose(pre_grasp_pose)\n\n        if not approach_success:\n            return {\'success\': False, \'reason\': \'Failed to reach approach pose\'}\n\n        # 2. Grasp approach - move to final grasp position\n        grasp_success = self.execute_grasp_approach(grasp_plan, object_info)\n\n        if not grasp_success:\n            return {\'success\': False, \'reason\': \'Grasp approach failed\'}\n\n        # 3. Grasp execution - close hand and apply appropriate forces\n        final_success = self.execute_grasp_execution(grasp_plan, object_info)\n\n        return {\n            \'success\': final_success,\n            \'grasp_quality\': self.estimate_grasp_quality(grasp_plan, object_info)\n        }\n\n    def calculate_pre_grasp_pose(self, grasp_plan):\n        """\n        Calculate pre-grasp pose (typically 5-10cm before final grasp)\n        """\n        final_pose = grasp_plan[\'pose\']\n        approach_dir = grasp_plan[\'approach_direction\']\n\n        # Move back along approach direction\n        pre_grasp_pose = final_pose.copy()\n        pre_grasp_pose[:3, 3] -= 0.05 * approach_dir  # 5cm back\n\n        return pre_grasp_pose\n\n    def move_to_approach_pose(self, pre_grasp_pose):\n        """\n        Move hand to pre-grasp position\n        """\n        # Use trajectory planning to move to pre-grasp pose\n        # Consider obstacles and joint limits\n        try:\n            trajectory = self.plan_hand_trajectory(pre_grasp_pose)\n            self.execute_trajectory(trajectory)\n            return True\n        except Exception as e:\n            print(f"Approach trajectory planning failed: {e}")\n            return False\n\n    def execute_grasp_approach(self, grasp_plan, object_info):\n        """\n        Execute the final approach to make contact with object\n        """\n        final_pose = grasp_plan[\'pose\']\n        approach_dir = grasp_plan[\'approach_direction\']\n\n        # Use compliant control for approach\n        # Move slowly with force feedback\n        success = self.move_with_compliance(\n            final_pose, approach_dir, object_info\n        )\n\n        return success\n\n    def execute_grasp_execution(self, grasp_plan, object_info):\n        """\n        Execute the actual grasp (closing hand, applying forces)\n        """\n        # Determine appropriate grasp force based on object properties\n        required_force = self.calculate_required_grasp_force(object_info)\n\n        # Close hand with appropriate force\n        success = self.close_hand_with_force_control(\n            grasp_plan[\'grasp_width\'], required_force\n        )\n\n        return success\n\n    def calculate_required_grasp_force(self, object_info):\n        """\n        Calculate required grasp force based on object properties\n        """\n        object_weight = object_info[\'weight\']\n        safety_factor = 3.0  # Safety factor for static friction\n        gravity = 9.81\n        friction_coefficient = 0.5  # Typical for robot fingertips\n\n        # Calculate minimum required force to prevent slip\n        min_force = (object_weight * gravity) / friction_coefficient\n\n        # Apply safety factor\n        required_force = min_force * safety_factor\n\n        # Limit to maximum safe force\n        max_safe_force = 50.0  # N - adjust based on hand capabilities\n        return min(required_force, max_safe_force)\n\n    def close_hand_with_force_control(self, target_width, target_force):\n        """\n        Close hand fingers with force control\n        """\n        # This would interface with hand controller\n        # Use position control until contact, then switch to force control\n        current_width = self.get_hand_width()\n\n        # Position control phase\n        while current_width > target_width and self.get_contact_force() < target_force * 0.1:\n            self.set_hand_position(current_width - 0.001)  # Move 1mm closer\n            current_width = self.get_hand_width()\n\n        # Force control phase\n        while self.get_contact_force() < target_force * 0.9:  # 90% of target\n            # Apply small additional closing force\n            self.apply_finger_force(target_force * 0.1)\n\n        return True  # Simplified success\n\n    def move_with_compliance(self, target_pose, approach_dir, object_info):\n        """\n        Move to target with compliant control to handle contact\n        """\n        # Use impedance control or admittance control\n        current_pose = self.get_hand_pose()\n\n        # Calculate trajectory in small steps\n        displacement = target_pose[:3, 3] - current_pose[:3, 3]\n        distance = np.linalg.norm(displacement)\n\n        if distance > 0:\n            direction = displacement / distance\n            step_size = 0.001  # 1mm steps\n\n            steps = int(distance / step_size)\n            for i in range(steps):\n                # Calculate intermediate pose\n                intermediate_pos = current_pose[:3, 3] + (i * step_size) * direction\n                intermediate_pose = current_pose.copy()\n                intermediate_pose[:3, 3] = intermediate_pos\n\n                # Apply compliant control\n                self.move_to_pose_with_compliance(intermediate_pose, approach_dir)\n\n                # Check for contact\n                if self.detect_contact():\n                    # Object contacted - adjust behavior\n                    return True\n\n        return True\n\n    def plan_hand_trajectory(self, target_pose):\n        """\n        Plan collision-free trajectory for hand\n        """\n        # Use path planning algorithms (RRT, PRM, etc.)\n        # Consider whole-body configuration to avoid self-collisions\n        # Simplified as an example\n        return [target_pose]  # Direct trajectory (unsafe in practice)\n\n    def execute_trajectory(self, trajectory):\n        """\n        Execute planned trajectory\n        """\n        # Send trajectory to motion controller\n        pass\n\n    def get_hand_pose(self):\n        """\n        Get current hand pose\n        """\n        # Interface with robot state\n        return np.eye(4)  # Placeholder\n\n    def get_contact_force(self):\n        """\n        Get current contact force from tactile sensors\n        """\n        # Interface with force/torque sensors\n        return 0.0  # Placeholder\n\n    def get_hand_width(self):\n        """\n        Get current hand aperture\n        """\n        # Interface with hand sensors\n        return 0.1  # Placeholder\n\n    def set_hand_position(self, position):\n        """\n        Set hand finger position\n        """\n        pass\n\n    def apply_finger_force(self, force):\n        """\n        Apply specific force to fingers\n        """\n        pass\n\n    def detect_contact(self):\n        """\n        Detect if hand has made contact with object\n        """\n        # Use force sensors, tactile sensors, or current feedback\n        return False  # Placeholder\n\n    def move_to_pose_with_compliance(self, target_pose, approach_dir):\n        """\n        Move to pose with compliance control\n        """\n        # Implement compliant control strategy\n        pass\n\n    def estimate_grasp_quality(self, grasp_plan, object_info):\n        """\n        Estimate the quality of the executed grasp\n        """\n        # Consider:\n        # - Force distribution across contact points\n        # - Object stability\n        # - Grasp robustness to perturbations\n        # - Task requirements\n\n        # Simplified quality estimation\n        grasp_type = grasp_plan[\'type\']\n        object_weight = object_info[\'weight\']\n\n        base_quality = 0.8 if grasp_type in [\'power\', \'top\'] else 0.6\n\n        # Reduce quality for heavy objects\n        if object_weight > 2.0:\n            base_quality *= (2.0 / object_weight) ** 0.3\n\n        return base_quality\n'})}),"\n",(0,o.jsx)(e.h2,{id:"bimanual-manipulation",children:"Bimanual Manipulation"}),"\n",(0,o.jsx)(e.h3,{id:"coordinated-two-hand-manipulation",children:"Coordinated Two-Hand Manipulation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class BimanualManipulator:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.left_arm_controller = self.model.get_arm_controller('left')\n        self.right_arm_controller = self.model.get_arm_controller('right')\n        self.coordination_planner = BimanualCoordinationPlanner(robot_model)\n\n    def execute_bimanual_task(self, task_description, object_info):\n        \"\"\"\n        Execute a bimanual manipulation task\n        \"\"\"\n        # Parse task description\n        task_type = task_description['type']\n        task_params = task_description.get('parameters', {})\n\n        if task_type == 'lifting':\n            return self.execute_lift_task(object_info, task_params)\n        elif task_type == 'assembly':\n            return self.execute_assembly_task(object_info, task_params)\n        elif task_type == 'transport':\n            return self.execute_transport_task(object_info, task_params)\n        elif task_type == 'reorienting':\n            return self.execute_reorient_task(object_info, task_params)\n        else:\n            raise ValueError(f\"Unknown bimanual task type: {task_type}\")\n\n    def execute_lift_task(self, object_info, params):\n        \"\"\"\n        Execute bimanual lifting task\n        \"\"\"\n        object_pose = object_info['pose']\n        object_dims = object_info['dimensions']\n        object_weight = object_info['weight']\n\n        # Plan coordinated grasp positions\n        grasp_poses = self.plan_lift_grasps(object_info, params)\n\n        # Execute coordinated approach\n        approach_success = self.execute_coordinated_approach(grasp_poses)\n\n        if not approach_success:\n            return {'success': False, 'reason': 'Approach failed'}\n\n        # Execute coordinated grasp\n        grasp_success = self.execute_coordinated_grasp(grasp_poses, object_info)\n\n        if not grasp_success:\n            return {'success': False, 'reason': 'Grasp failed'}\n\n        # Execute coordinated lift\n        lift_success = self.execute_coordinated_lift(grasp_poses, object_info)\n\n        return {\n            'success': lift_success,\n            'object_lifted': lift_success\n        }\n\n    def plan_lift_grasps(self, object_info, params):\n        \"\"\"\n        Plan coordinated grasp poses for lifting\n        \"\"\"\n        object_pose = object_info['pose']\n        object_dims = object_info['dimensions']\n\n        # Determine optimal grasp points for lifting\n        # Typically symmetrical positions on opposite sides of object\n        grasp_distance = min(object_dims[0], object_dims[1]) * 0.8  # 80% of smaller dimension\n        grasp_height = object_dims[2] / 2  # Grasp at object center height\n\n        # Calculate left and right grasp positions\n        left_pos = object_pose[:3, 3].copy()\n        left_pos[0] -= grasp_distance / 2  # Move left\n        left_pos[2] += grasp_height  # Move up to center\n\n        right_pos = object_pose[:3, 3].copy()\n        right_pos[0] += grasp_distance / 2  # Move right\n        right_pos[2] += grasp_height  # Move up to center\n\n        # Calculate appropriate orientations\n        left_orientation = object_pose[:3, :3]  # Copy object orientation\n        right_orientation = object_pose[:3, :3]\n\n        return {\n            'left_grasp': self.create_grasp_pose(left_pos, left_orientation),\n            'right_grasp': self.create_grasp_pose(right_pos, right_orientation)\n        }\n\n    def create_grasp_pose(self, position, orientation):\n        \"\"\"\n        Create a grasp pose matrix\n        \"\"\"\n        pose = np.eye(4)\n        pose[:3, 3] = position\n        pose[:3, :3] = orientation\n        return pose\n\n    def execute_coordinated_approach(self, grasp_poses):\n        \"\"\"\n        Execute coordinated approach to grasp positions\n        \"\"\"\n        # Plan synchronized trajectories for both arms\n        left_traj = self.plan_arm_trajectory('left', grasp_poses['left_grasp'])\n        right_traj = self.plan_arm_trajectory('right', grasp_poses['right_grasp'])\n\n        # Check for collisions between arms and with environment\n        if not self.check_bimanual_collision(left_traj, right_traj):\n            return False\n\n        # Execute trajectories simultaneously\n        return self.execute_synchronized_trajectories(left_traj, right_traj)\n\n    def execute_coordinated_grasp(self, grasp_poses, object_info):\n        \"\"\"\n        Execute coordinated grasp with both hands\n        \"\"\"\n        # Close both hands simultaneously with appropriate forces\n        left_force = self.calculate_grasp_force(object_info, 'left')\n        right_force = self.calculate_grasp_force(object_info, 'right')\n\n        # Execute grasp with coordination\n        left_success = self.close_hand('left', left_force)\n        right_success = self.close_hand('right', right_force)\n\n        return left_success and right_success\n\n    def execute_coordinated_lift(self, grasp_poses, object_info):\n        \"\"\"\n        Execute coordinated lifting motion\n        \"\"\"\n        # Calculate lift trajectory\n        lift_height = 0.1  # Lift 10cm\n        current_poses = {\n            'left': self.get_hand_pose('left'),\n            'right': self.get_hand_pose('right')\n        }\n\n        target_poses = {\n            'left': current_poses['left'].copy(),\n            'right': current_poses['right'].copy()\n        }\n\n        # Move both hands up by lift_height\n        target_poses['left'][2, 3] += lift_height\n        target_poses['right'][2, 3] += lift_height\n\n        # Execute synchronized lift\n        left_traj = self.plan_arm_trajectory('left', target_poses['left'])\n        right_traj = self.plan_arm_trajectory('right', target_poses['right'])\n\n        return self.execute_synchronized_trajectories(left_traj, right_traj)\n\n    def plan_arm_trajectory(self, arm_side, target_pose):\n        \"\"\"\n        Plan trajectory for single arm\n        \"\"\"\n        # This would use motion planning algorithms\n        # Consider: obstacles, joint limits, balance constraints\n        return [target_pose]  # Simplified\n\n    def check_bimanual_collision(self, left_trajectory, right_trajectory):\n        \"\"\"\n        Check for collisions between arms and environment\n        \"\"\"\n        # Check self-collision between arms\n        # Check collision with environment\n        # Check balance constraints\n        return True  # Simplified\n\n    def execute_synchronized_trajectories(self, left_trajectory, right_trajectory):\n        \"\"\"\n        Execute trajectories for both arms simultaneously\n        \"\"\"\n        # This would involve low-level control coordination\n        # Ensure both arms move in synchronized manner\n        return True  # Simplified\n\n    def calculate_grasp_force(self, object_info, arm_side):\n        \"\"\"\n        Calculate appropriate grasp force for object\n        \"\"\"\n        object_weight = object_info['weight']\n        # Distribute weight between two arms\n        force_per_arm = (object_weight * 9.81) / 2\n        safety_factor = 2.0\n        return force_per_arm * safety_factor\n\n    def close_hand(self, arm_side, force):\n        \"\"\"\n        Close hand with specified force\n        \"\"\"\n        # Interface with hand controller\n        return True  # Simplified\n\n    def get_hand_pose(self, arm_side):\n        \"\"\"\n        Get current hand pose\n        \"\"\"\n        # Interface with robot state\n        return np.eye(4)  # Simplified\n\n    def execute_assembly_task(self, object_info, params):\n        \"\"\"\n        Execute bimanual assembly task\n        \"\"\"\n        # Complex assembly involving multiple objects\n        # Coordination of insertion, alignment, and force control\n        pass\n\n    def execute_transport_task(self, object_info, params):\n        \"\"\"\n        Execute bimanual transport task\n        \"\"\"\n        # Transport object while maintaining stable grasp\n        # Path planning considering bimanual constraints\n        pass\n\n    def execute_reorient_task(self, object_info, params):\n        \"\"\"\n        Execute bimanual object reorientation\n        \"\"\"\n        # Rotate object using coordinated hand movements\n        # Maintain grasp stability during rotation\n        pass\n\nclass BimanualCoordinationPlanner:\n    def __init__(self, robot_model):\n        self.model = robot_model\n\n    def plan_coordinated_motion(self, task, object_info):\n        \"\"\"\n        Plan coordinated motion for bimanual tasks\n        \"\"\"\n        # Consider:\n        # - Kinematic constraints of both arms\n        # - Balance requirements\n        # - Task-specific coordination patterns\n        # - Force distribution\n        pass\n\n    def generate_coordination_patterns(self, task_type):\n        \"\"\"\n        Generate typical coordination patterns for common tasks\n        \"\"\"\n        patterns = {\n            'lifting': {\n                'symmetry': 'high',\n                'synchronization': 'high',\n                'force_distribution': 'equal'\n            },\n            'carrying': {\n                'symmetry': 'medium',\n                'synchronization': 'medium',\n                'force_distribution': 'adjustable'\n            },\n            'reorienting': {\n                'symmetry': 'low',\n                'synchronization': 'task_dependent',\n                'force_distribution': 'asymmetric'\n            }\n        }\n\n        return patterns.get(task_type, patterns['lifting'])\n"})}),"\n",(0,o.jsx)(e.h2,{id:"whole-body-manipulation",children:"Whole-Body Manipulation"}),"\n",(0,o.jsx)(e.h3,{id:"integration-of-manipulation-and-locomotion",children:"Integration of Manipulation and Locomotion"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class WholeBodyManipulationController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.manipulation_controller = self.model.manipulation_controller\n        self.balance_controller = self.model.balance_controller\n        self.locomotion_controller = self.model.locomotion_controller\n\n        # Task priority levels\n        self.priorities = {\n            \'balance\': 1,      # Highest priority\n            \'collision_avoidance\': 2,\n            \'manipulation\': 3,\n            \'posture\': 4       # Lowest priority\n        }\n\n    def execute_whole_body_task(self, task_description):\n        """\n        Execute task requiring coordination of manipulation and other systems\n        """\n        # Parse task requirements\n        primary_task = task_description[\'primary_task\']\n        constraints = task_description.get(\'constraints\', {})\n\n        # Plan whole-body motion considering all constraints\n        motion_plan = self.plan_whole_body_motion(primary_task, constraints)\n\n        # Execute with priority-based control\n        execution_result = self.execute_with_priorities(motion_plan)\n\n        return execution_result\n\n    def plan_whole_body_motion(self, primary_task, constraints):\n        """\n        Plan motion considering all body parts and constraints\n        """\n        # Use whole-body optimization\n        # Minimize: ||Ax - b||\xb2\n        # Subject to: Cx = d (equality constraints)\n        #            Gx <= h (inequality constraints)\n\n        # Where x includes all joint positions, CoM position, ZMP, etc.\n\n        # For this example, use hierarchical approach\n        return self.hierarchical_motion_planning(primary_task, constraints)\n\n    def hierarchical_motion_planning(self, primary_task, constraints):\n        """\n        Plan motion using hierarchical approach\n        """\n        # 1. Balance constraints (highest priority)\n        balance_solution = self.plan_balance_motion(constraints)\n\n        # 2. Collision avoidance\n        collision_free_solution = self.add_collision_avoidance(\n            balance_solution, constraints\n        )\n\n        # 3. Manipulation task\n        manipulation_solution = self.add_manipulation_task(\n            collision_free_solution, primary_task\n        )\n\n        # 4. Posture optimization (lowest priority)\n        final_solution = self.add_posture_optimization(\n            manipulation_solution, constraints\n        )\n\n        return final_solution\n\n    def plan_balance_motion(self, constraints):\n        """\n        Plan motion ensuring balance is maintained\n        """\n        # Calculate CoM trajectory that maintains stability\n        if \'balance_point\' in constraints:\n            balance_point = constraints[\'balance_point\']\n        else:\n            # Use support polygon center\n            support_polygon = self.model.calculate_support_polygon()\n            balance_point = np.array([\n                (support_polygon[\'min_x\'] + support_polygon[\'max_x\']) / 2,\n                (support_polygon[\'min_y\'] + support_polygon[\'max_y\']) / 2\n            ])\n\n        # Plan CoM trajectory to stay near balance point\n        return {\n            \'com_trajectory\': self.generate_com_trajectory(balance_point),\n            \'zmp_constraints\': self.calculate_zmp_constraints(),\n            \'joint_limits\': self.model.get_joint_limits()\n        }\n\n    def add_collision_avoidance(self, balance_solution, constraints):\n        """\n        Add collision avoidance to existing solution\n        """\n        # Use null-space projection or optimization\n        # to avoid obstacles while maintaining balance\n\n        solution = balance_solution.copy()\n\n        if \'obstacles\' in constraints:\n            # Calculate collision-free configuration\n            solution[\'collision_free_config\'] = self.plan_collision_free_path(\n                solution, constraints[\'obstacles\']\n            )\n\n        return solution\n\n    def add_manipulation_task(self, collision_solution, primary_task):\n        """\n        Add manipulation task to existing solution\n        """\n        solution = collision_solution.copy()\n\n        # Solve manipulation task in null space of higher-priority tasks\n        if primary_task[\'type\'] == \'reach\':\n            solution[\'manipulation_solution\'] = self.plan_reach_task(\n                primary_task[\'target\'], solution\n            )\n        elif primary_task[\'type\'] == \'grasp\':\n            solution[\'manipulation_solution\'] = self.plan_grasp_task(\n                primary_task[\'object\'], solution\n            )\n        elif primary_task[\'type\'] == \'transport\':\n            solution[\'manipulation_solution\'] = self.plan_transport_task(\n                primary_task[\'path\'], solution\n            )\n\n        return solution\n\n    def add_posture_optimization(self, manipulation_solution, constraints):\n        """\n        Optimize posture while maintaining higher-priority tasks\n        """\n        solution = manipulation_solution.copy()\n\n        # Optimize for joint centering, energy efficiency, etc.\n        # in the null space of other constraints\n        solution[\'posture_solution\'] = self.optimize_posture(\n            solution, constraints\n        )\n\n        return solution\n\n    def execute_with_priorities(self, motion_plan):\n        """\n        Execute motion plan respecting priority hierarchy\n        """\n        # Use task-priority based control\n        # Control law: \u03c4 = \u03c4_balance + N_balance * (\u03c4_collision + N_collision * (\u03c4_manipulation + ...))\n\n        current_state = self.model.get_current_state()\n\n        # Calculate balance control (highest priority)\n        balance_control = self.balance_controller.compute_balance_control(\n            current_state, motion_plan[\'com_trajectory\']\n        )\n\n        # Calculate collision avoidance in balance null space\n        N_balance = self.calculate_null_space_projector(balance_control[\'jacobian\'])\n        collision_control = self.compute_collision_control(\n            current_state, motion_plan\n        )\n        collision_control = N_balance @ collision_control\n\n        # Calculate manipulation control in previous null spaces\n        N_collision = self.calculate_null_space_projector(collision_control[\'jacobian\'])\n        manipulation_control = self.manipulation_controller.compute_control(\n            current_state, motion_plan[\'manipulation_solution\']\n        )\n        manipulation_control = N_collision @ manipulation_control\n\n        # Combine all controls\n        total_control = balance_control[\'torques\'] + collision_control + manipulation_control\n\n        # Apply control to robot\n        self.model.apply_control(total_control)\n\n        return {\n            \'success\': True,\n            \'balance_maintained\': self.check_balance(total_control),\n            \'task_completed\': self.check_task_completion(motion_plan)\n        }\n\n    def calculate_null_space_projector(self, jacobian):\n        """\n        Calculate null space projector I - J#J\n        """\n        # Calculate pseudo-inverse\n        J_pinv = np.linalg.pinv(jacobian)\n        # Calculate null space projector\n        I = np.eye(jacobian.shape[1])\n        N = I - J_pinv @ jacobian\n        return N\n\n    def compute_collision_control(self, current_state, motion_plan):\n        """\n        Compute collision avoidance control\n        """\n        # Use artificial potential fields or other methods\n        pass\n\n    def check_balance(self, control_output):\n        """\n        Check if balance is maintained\n        """\n        # Verify ZMP is within support polygon\n        # Check joint limit violations\n        # Check for excessive torques\n        return True  # Simplified\n\n    def check_task_completion(self, motion_plan):\n        """\n        Check if manipulation task is completed\n        """\n        # Check if end-effector reached target\n        # Check if grasp is stable\n        # Check if object is transported successfully\n        return True  # Simplified\n\n    def generate_com_trajectory(self, balance_point):\n        """\n        Generate CoM trajectory around balance point\n        """\n        # Create trajectory that keeps CoM near balance point\n        # while allowing for manipulation-related movements\n        pass\n\n    def calculate_zmp_constraints(self):\n        """\n        Calculate ZMP constraints for balance\n        """\n        # Define ZMP regions that maintain balance\n        pass\n\n    def plan_reach_task(self, target, current_solution):\n        """\n        Plan reaching motion\n        """\n        pass\n\n    def plan_grasp_task(self, object_info, current_solution):\n        """\n        Plan grasping motion\n        """\n        pass\n\n    def plan_transport_task(self, path, current_solution):\n        """\n        Plan object transport motion\n        """\n        pass\n\n    def optimize_posture(self, current_solution, constraints):\n        """\n        Optimize robot posture\n        """\n        pass\n'})}),"\n",(0,o.jsx)(e.h2,{id:"advanced-manipulation-techniques",children:"Advanced Manipulation Techniques"}),"\n",(0,o.jsx)(e.h3,{id:"variable-impedance-control",children:"Variable Impedance Control"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class VariableImpedanceController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.default_impedance = {\n            'M': np.eye(6) * 1.0,    # Mass matrix\n            'D': np.eye(6) * 10.0,   # Damping matrix\n            'K': np.eye(6) * 100.0   # Stiffness matrix\n        }\n\n    def set_task_adaptive_impedance(self, task_type, object_properties):\n        \"\"\"\n        Set impedance parameters based on task and object properties\n        \"\"\"\n        if task_type == 'delicate':\n            # Low stiffness for fragile objects\n            return {\n                'M': self.default_impedance['M'] * 0.5,\n                'D': self.default_impedance['D'] * 0.8,\n                'K': self.default_impedance['K'] * 0.2  # Very low stiffness\n            }\n        elif task_type == 'heavy_object':\n            # High stiffness for heavy objects\n            return {\n                'M': self.default_impedance['M'] * 2.0,\n                'D': self.default_impedance['D'] * 1.5,\n                'K': self.default_impedance['K'] * 2.0\n            }\n        elif task_type == 'assembly':\n            # High stiffness in constrained directions, low in others\n            K = self.default_impedance['K'].copy()\n            # For insertion tasks, high stiffness perpendicular to insertion direction\n            # low stiffness along insertion direction\n            return {\n                'M': self.default_impedance['M'],\n                'D': self.default_impedance['D'],\n                'K': K\n            }\n        else:\n            # Default impedance\n            return self.default_impedance\n\n    def execute_variable_impedance_manipulation(self, task_description, object_info):\n        \"\"\"\n        Execute manipulation with variable impedance\n        \"\"\"\n        # Determine appropriate impedance based on task\n        impedance_params = self.set_task_adaptive_impedance(\n            task_description['type'], object_info\n        )\n\n        # Execute task with specified impedance\n        return self.execute_with_impedance_control(\n            task_description, object_info, impedance_params\n        )\n\n    def execute_with_impedance_control(self, task_description, object_info, impedance_params):\n        \"\"\"\n        Execute task with specified impedance parameters\n        \"\"\"\n        # Use impedance control law: \u03c4 = J^T * (K*(x_d - x) + D*(v_d - v) + M*(a_d - a))\n        pass\n"})}),"\n",(0,o.jsx)(e.h3,{id:"learning-based-manipulation",children:"Learning-Based Manipulation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class LearningBasedManipulator:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.experience_buffer = []\n        self.manipulation_policy = self.initialize_policy_network()\n\n    def initialize_policy_network(self):\n        """\n        Initialize neural network for manipulation policy\n        """\n        import torch\n        import torch.nn as nn\n\n        class ManipulationPolicy(nn.Module):\n            def __init__(self, state_dim=50, action_dim=28):\n                super().__init__()\n                self.network = nn.Sequential(\n                    nn.Linear(state_dim, 256),\n                    nn.ReLU(),\n                    nn.Linear(256, 256),\n                    nn.ReLU(),\n                    nn.Linear(256, 128),\n                    nn.ReLU(),\n                    nn.Linear(128, action_dim)\n                )\n\n            def forward(self, state):\n                return self.network(state)\n\n        return ManipulationPolicy()\n\n    def learn_from_demonstration(self, demonstration_data):\n        """\n        Learn manipulation skills from human demonstrations\n        """\n        # Train policy network on demonstration data\n        # Use behavioral cloning or other imitation learning methods\n        pass\n\n    def adapt_to_new_objects(self, object_properties, task_performance):\n        """\n        Adapt manipulation strategy based on object properties and performance\n        """\n        # Use meta-learning or online adaptation\n        # Adjust grasp parameters, force control, trajectory planning\n        pass\n\n    def execute_learning_based_manipulation(self, task_description, object_info):\n        """\n        Execute manipulation using learned policy\n        """\n        # Encode task and object information as state\n        state = self.encode_state(task_description, object_info)\n\n        # Get action from learned policy\n        action = self.manipulation_policy(state)\n\n        # Execute action with safety checks\n        return self.execute_with_safety(action, object_info)\n\n    def encode_state(self, task_description, object_info):\n        """\n        Encode task and object information as neural network input\n        """\n        # Combine robot state, object properties, task goals\n        # into fixed-size state vector\n        pass\n\n    def execute_with_safety(self, action, object_info):\n        """\n        Execute action with safety constraints\n        """\n        # Apply safety limits, check for collisions, monitor forces\n        pass\n'})}),"\n",(0,o.jsx)(e.h2,{id:"simulation-and-testing-framework",children:"Simulation and Testing Framework"}),"\n",(0,o.jsx)(e.h3,{id:"manipulation-testing-environment",children:"Manipulation Testing Environment"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class ManipulationTester:\n    def __init__(self, robot_model, controller):\n        self.model = robot_model\n        self.controller = controller\n        self.simulator = self.initialize_physics_simulator()\n\n    def initialize_physics_simulator(self):\n        \"\"\"\n        Initialize physics simulator for manipulation testing\n        \"\"\"\n        return {\n            'gravity': 9.81,\n            'timestep': 0.001,\n            'contact_model': 'soft',\n            'friction_coefficients': [0.5, 0.7, 0.3],  # Various materials\n            'object_properties': {\n                'light': {'weight': 0.1, 'fragile': True},\n                'medium': {'weight': 1.0, 'fragile': False},\n                'heavy': {'weight': 5.0, 'fragile': False}\n            }\n        }\n\n    def test_grasp_stability(self, object_type, grasp_type):\n        \"\"\"\n        Test grasp stability for different object and grasp combinations\n        \"\"\"\n        # Setup test scenario\n        object_info = self.create_test_object(object_type)\n        grasp_plan = self.create_test_grasp(object_info, grasp_type)\n\n        # Execute grasp\n        result = self.controller.execute_grasp(grasp_plan, object_info)\n\n        # Apply perturbations to test stability\n        stability_result = self.test_grasp_stability_with_perturbations(\n            result, object_info\n        )\n\n        return stability_result\n\n    def test_bimanual_coordination(self, task_type):\n        \"\"\"\n        Test bimanual manipulation coordination\n        \"\"\"\n        # Setup bimanual task\n        task_description = {\n            'type': task_type,\n            'parameters': self.get_task_parameters(task_type)\n        }\n\n        # Execute task\n        result = self.controller.execute_bimanual_task(task_description, {})\n\n        # Evaluate coordination metrics\n        coordination_metrics = self.evaluate_coordination_metrics(result)\n\n        return {\n            'success': result['success'],\n            'coordination_score': coordination_metrics['score'],\n            'balance_maintained': coordination_metrics['balance'],\n            'task_completion_time': coordination_metrics['time']\n        }\n\n    def test_variable_impedance_performance(self, task_scenarios):\n        \"\"\"\n        Test variable impedance control performance\n        \"\"\"\n        results = []\n        for scenario in task_scenarios:\n            result = self.execute_variable_impedance_test(scenario)\n            results.append(result)\n\n        return results\n\n    def create_test_object(self, object_type):\n        \"\"\"\n        Create test object with specified properties\n        \"\"\"\n        base_props = {\n            'light': {'weight': 0.1, 'dimensions': [0.05, 0.05, 0.05], 'material': 'plastic'},\n            'medium': {'weight': 1.0, 'dimensions': [0.1, 0.1, 0.1], 'material': 'wood'},\n            'heavy': {'weight': 5.0, 'dimensions': [0.15, 0.15, 0.15], 'material': 'metal'}\n        }\n\n        props = base_props[object_type].copy()\n        props['pose'] = np.eye(4)  # Default pose\n        props['pose'][2, 3] = 0.8  # Place on table at 80cm height\n\n        return props\n\n    def create_test_grasp(self, object_info, grasp_type):\n        \"\"\"\n        Create test grasp for given object and grasp type\n        \"\"\"\n        # Use grasp planner to generate appropriate grasp\n        planner = HumanoidGraspPlanner(self.model)\n        current_state = self.model.get_default_state()\n\n        return planner.plan_grasp(object_info, current_state)\n\n    def test_grasp_stability_with_perturbations(self, grasp_result, object_info):\n        \"\"\"\n        Test grasp stability by applying perturbations\n        \"\"\"\n        if not grasp_result['success']:\n            return {'stability': 0.0, 'success': False}\n\n        # Apply various perturbations to test grasp robustness\n        perturbations = [\n            {'type': 'force', 'direction': [1, 0, 0], 'magnitude': 5.0},  # 5N horizontal\n            {'type': 'force', 'direction': [0, 1, 0], 'magnitude': 5.0},  # 5N lateral\n            {'type': 'force', 'direction': [0, 0, -1], 'magnitude': 2.0},  # 2N downward\n            {'type': 'torque', 'axis': [1, 0, 0], 'magnitude': 0.5},  # Torque around x\n            {'type': 'torque', 'axis': [0, 1, 0], 'magnitude': 0.5},  # Torque around y\n        ]\n\n        successful_perturbations = 0\n        total_perturbations = len(perturbations)\n\n        for perturbation in perturbations:\n            if self.apply_perturbation_and_check_grasp(object_info, perturbation):\n                successful_perturbations += 1\n\n        stability_score = successful_perturbations / total_perturbations\n\n        return {\n            'stability': stability_score,\n            'success': True,\n            'perturbation_results': [True] * successful_perturbations + [False] * (total_perturbations - successful_perturbations)\n        }\n\n    def apply_perturbation_and_check_grasp(self, object_info, perturbation):\n        \"\"\"\n        Apply perturbation and check if grasp is maintained\n        \"\"\"\n        # Apply perturbation force/torque to object\n        # Simulate for short duration\n        # Check if grasp is still stable\n        return True  # Simplified\n\n    def get_task_parameters(self, task_type):\n        \"\"\"\n        Get parameters for specific task type\n        \"\"\"\n        params = {\n            'lifting': {'height': 0.2, 'distance': 0.3},\n            'assembly': {'precision': 0.001, 'force_limit': 10.0},\n            'transport': {'path_length': 1.0, 'obstacles': []},\n            'reorienting': {'angle_range': np.pi/2, 'speed': 0.1}\n        }\n\n        return params.get(task_type, {})\n\n    def evaluate_coordination_metrics(self, result):\n        \"\"\"\n        Evaluate bimanual coordination metrics\n        \"\"\"\n        return {\n            'score': 0.8,  # Placeholder\n            'balance': True,  # Placeholder\n            'time': 5.0  # Placeholder\n        }\n\n    def execute_variable_impedance_test(self, scenario):\n        \"\"\"\n        Execute variable impedance control test\n        \"\"\"\n        return {'success': True, 'metrics': {}}  # Placeholder\n"})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid manipulation is a complex and multifaceted field that requires coordination of multiple systems:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dual-Arm Coordination"}),": Managing two arms while considering whole-body constraints"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Grasp Planning"}),": Planning stable and appropriate grasps considering object properties"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Whole-Body Integration"}),": Coordinating manipulation with balance, locomotion, and other systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Advanced Control"}),": Using variable impedance, learning-based approaches, and adaptive control"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Testing and Validation"}),": Comprehensive testing to ensure robust performance"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"The challenges in humanoid manipulation stem from the need to coordinate multiple objectives (manipulation performance, balance, collision avoidance, etc.) while dealing with the complexity of full-body systems. Success requires sophisticated algorithms that can handle the redundancy and constraints inherent in humanoid robots."}),"\n",(0,o.jsx)(e.p,{children:"The field continues to evolve with advances in machine learning, optimization, and control theory, enabling humanoid robots to perform increasingly complex manipulation tasks in real-world environments."}),"\n",(0,o.jsx)(e.p,{children:"In the next section, we'll explore human-robot interaction, which builds upon manipulation capabilities to enable natural and intuitive interaction between humans and humanoid robots."})]})}function _(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(p,{...n})}):p(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>r});var i=t(6540);const o={},a=i.createContext(o);function s(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);