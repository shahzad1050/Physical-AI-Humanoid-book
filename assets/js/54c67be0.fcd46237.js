"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[7271],{5275:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>_,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module3/sim-to-real","title":"Sim-to-Real Transfer Techniques","description":"Introduction to Sim-to-Real Transfer","source":"@site/docs/module3/sim-to-real.md","sourceDirName":"module3","slug":"/module3/sim-to-real","permalink":"/Physical-AI-Humanoid-book/docs/module3/sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/user/physical-ai-humanoid-robotics/tree/main/docs/module3/sim-to-real.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Reinforcement Learning for Control","permalink":"/Physical-AI-Humanoid-book/docs/module3/reinforcement-learning"},"next":{"title":"Balance and Postural Control","permalink":"/Physical-AI-Humanoid-book/docs/module4/balance-control"}}');var i=r(4848),t=r(8453);const s={},o="Sim-to-Real Transfer Techniques",l={},c=[{value:"Introduction to Sim-to-Real Transfer",id:"introduction-to-sim-to-real-transfer",level:2},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:2},{value:"Sources of the Reality Gap",id:"sources-of-the-reality-gap",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physics Domain Randomization",id:"physics-domain-randomization",level:3},{value:"Domain Adaptation Techniques",id:"domain-adaptation-techniques",level:2},{value:"Unsupervised Domain Adaptation",id:"unsupervised-domain-adaptation",level:3},{value:"SimGAN (Simulation-to-Reality with GANs)",id:"simgan-simulation-to-reality-with-gans",level:3},{value:"System Identification and System Modeling",id:"system-identification-and-system-modeling",level:2},{value:"System Identification for Dynamics Matching",id:"system-identification-for-dynamics-matching",level:3},{value:"Adaptive Control and Online Learning",id:"adaptive-control-and-online-learning",level:2},{value:"Online Domain Adaptation",id:"online-domain-adaptation",level:3},{value:"Sensor Fusion and Calibration",id:"sensor-fusion-and-calibration",level:2},{value:"Multi-Sensor Calibration for Transfer",id:"multi-sensor-calibration-for-transfer",level:3},{value:"Robust Control Techniques",id:"robust-control-techniques",level:2},{value:"Robust Control for Domain Transfer",id:"robust-control-for-domain-transfer",level:3},{value:"Transfer Learning Approaches",id:"transfer-learning-approaches",level:2},{value:"Fine-tuning for Real-World Deployment",id:"fine-tuning-for-real-world-deployment",level:3},{value:"Validation and Testing Strategies",id:"validation-and-testing-strategies",level:2},{value:"Sim-to-Real Validation Framework",id:"sim-to-real-validation-framework",level:3},{value:"Best Practices for Successful Transfer",id:"best-practices-for-successful-transfer",level:2},{value:"1. Gradual Deployment Strategy",id:"1-gradual-deployment-strategy",level:3},{value:"2. Safety-First Approach",id:"2-safety-first-approach",level:3},{value:"Troubleshooting Common Transfer Issues",id:"troubleshooting-common-transfer-issues",level:2},{value:"1. Performance Degradation",id:"1-performance-degradation",level:3},{value:"2. Instability and Oscillation",id:"2-instability-and-oscillation",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sim-to-real-transfer-techniques",children:"Sim-to-Real Transfer Techniques"})}),"\n",(0,i.jsx)(n.h2,{id:"introduction-to-sim-to-real-transfer",children:"Introduction to Sim-to-Real Transfer"}),"\n",(0,i.jsx)(n.p,{children:"Sim-to-Real transfer, also known as domain transfer, is the process of taking models, policies, or systems trained in simulation and successfully deploying them on real robots. This is a critical challenge in robotics because simulations, while valuable for training and testing, inevitably differ from reality due to modeling inaccuracies, sensor noise, actuator dynamics, and environmental factors."}),"\n",(0,i.jsx)(n.h2,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,i.jsx)(n.h3,{id:"sources-of-the-reality-gap",children:"Sources of the Reality Gap"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap encompasses all differences between simulation and real-world performance:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visual Domain Gap"}),": Differences in appearance, lighting, textures, and camera characteristics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physics Domain Gap"}),": Differences in friction, mass, dynamics, and contact mechanics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor Domain Gap"}),": Differences in sensor noise, latency, and accuracy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator Domain Gap"}),": Differences in motor dynamics, delays, and precision"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environmental Domain Gap"}),": Differences in workspace conditions, disturbances, and objects"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Simulation Domain \u2192 Reality Gap \u2192 Real World Domain\r\n     \u2193                \u2193               \u2193\r\nPerfect models    Modeling errors   Physical world\r\nClean data      Sensor noise     Environmental\r\nNo delays       Actuator delays   disturbances\n"})}),"\n",(0,i.jsx)(n.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(n.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,i.jsx)(n.p,{children:"Domain randomization is one of the most effective techniques for creating robust policies that can handle domain shift:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class VisualDomainRandomizer:\r\n    def __init__(self):\r\n        self.randomization_params = {\r\n            'lighting': {\r\n                'intensity_range': (0.5, 2.0),\r\n                'color_temperature_range': (3000, 8000),\r\n                'position_variance': 0.5\r\n            },\r\n            'textures': {\r\n                'materials': ['metal', 'wood', 'plastic', 'fabric'],\r\n                'roughness_range': (0.1, 0.9),\r\n                'metallic_range': (0.0, 1.0)\r\n            },\r\n            'camera': {\r\n                'exposure_range': (-2.0, 2.0),\r\n                'white_balance_range': (0.8, 1.2),\r\n                'noise_std_range': (0.001, 0.02)\r\n            }\r\n        }\r\n\r\n    def randomize_visual_environment(self, scene):\r\n        \"\"\"Apply visual domain randomization to the scene\"\"\"\r\n        # Randomize lighting conditions\r\n        self.randomize_lighting(scene)\r\n\r\n        # Randomize material properties\r\n        self.randomize_materials(scene)\r\n\r\n        # Add camera noise\r\n        self.add_camera_noise(scene)\r\n\r\n        # Randomize textures and colors\r\n        self.randomize_textures(scene)\r\n\r\n    def randomize_lighting(self, scene):\r\n        \"\"\"Randomize lighting parameters\"\"\"\r\n        for light in scene.get_lights():\r\n            # Randomize intensity\r\n            intensity_factor = np.random.uniform(\r\n                self.randomization_params['lighting']['intensity_range'][0],\r\n                self.randomization_params['lighting']['intensity_range'][1]\r\n            )\r\n            light.set_intensity(light.base_intensity * intensity_factor)\r\n\r\n            # Randomize color temperature\r\n            color_temp = np.random.uniform(\r\n                self.randomization_params['lighting']['color_temperature_range'][0],\r\n                self.randomization_params['lighting']['color_temperature_range'][1]\r\n            )\r\n            light.set_color_temperature(color_temp)\r\n\r\n            # Randomize position\r\n            pos_variance = self.randomization_params['lighting']['position_variance']\r\n            random_offset = np.random.uniform(-pos_variance, pos_variance, 3)\r\n            light.set_position(light.base_position + random_offset)\r\n\r\n    def add_camera_noise(self, scene):\r\n        \"\"\"Add realistic camera noise\"\"\"\r\n        for camera in scene.get_cameras():\r\n            # Randomize noise parameters\r\n            noise_std = np.random.uniform(\r\n                self.randomization_params['camera']['noise_std_range'][0],\r\n                self.randomization_params['camera']['noise_std_range'][1]\r\n            )\r\n            camera.add_noise(std=noise_std)\r\n\r\n            # Randomize exposure\r\n            exposure = np.random.uniform(\r\n                self.randomization_params['camera']['exposure_range'][0],\r\n                self.randomization_params['camera']['exposure_range'][1]\r\n            )\r\n            camera.set_exposure(exposure)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"physics-domain-randomization",children:"Physics Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class PhysicsDomainRandomizer:\r\n    def __init__(self):\r\n        self.randomization_params = {\r\n            'friction': (0.1, 1.0),\r\n            'restitution': (0.0, 0.5),\r\n            'mass_multiplier': (0.8, 1.2),\r\n            'damping': (0.95, 1.05),\r\n            'gravity': (9.7, 9.9)\r\n        }\r\n\r\n    def randomize_physics_properties(self, scene):\r\n        \"\"\"Randomize physics properties in the simulation\"\"\"\r\n        # Randomize friction coefficients\r\n        self.randomize_friction(scene)\r\n\r\n        # Randomize restitution (bounciness)\r\n        self.randomize_restitution(scene)\r\n\r\n        # Randomize object masses\r\n        self.randomize_masses(scene)\r\n\r\n        # Randomize damping parameters\r\n        self.randomize_damping(scene)\r\n\r\n        # Randomize gravity\r\n        self.randomize_gravity(scene)\r\n\r\n    def randomize_friction(self, scene):\r\n        \"\"\"Randomize friction coefficients\"\"\"\r\n        for obj in scene.get_objects():\r\n            friction = np.random.uniform(\r\n                self.randomization_params['friction'][0],\r\n                self.randomization_params['friction'][1]\r\n            )\r\n            obj.set_friction(friction)\r\n\r\n    def randomize_masses(self, scene):\r\n        \"\"\"Randomize object masses\"\"\"\r\n        for obj in scene.get_objects():\r\n            mass_multiplier = np.random.uniform(\r\n                self.randomization_params['mass_multiplier'][0],\r\n                self.randomization_params['mass_multiplier'][1]\r\n            )\r\n            original_mass = obj.get_mass()\r\n            new_mass = original_mass * mass_multiplier\r\n            obj.set_mass(new_mass)\r\n\r\n    def randomize_damping(self, scene):\r\n        \"\"\"Randomize damping parameters\"\"\"\r\n        for obj in scene.get_objects():\r\n            linear_damping = obj.get_linear_damping() * np.random.uniform(\r\n                self.randomization_params['damping'][0],\r\n                self.randomization_params['damping'][1]\r\n            )\r\n            angular_damping = obj.get_angular_damping() * np.random.uniform(\r\n                self.randomization_params['damping'][0],\r\n                self.randomization_params['damping'][1]\r\n            )\r\n            obj.set_damping(linear_damping, angular_damping)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"domain-adaptation-techniques",children:"Domain Adaptation Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"unsupervised-domain-adaptation",children:"Unsupervised Domain Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\n\r\nclass DomainAdaptationNetwork(nn.Module):\r\n    def __init__(self, input_dim, feature_dim=256):\r\n        super(DomainAdaptationNetwork, self).__init__()\r\n\r\n        # Feature extractor\r\n        self.feature_extractor = nn.Sequential(\r\n            nn.Linear(input_dim, 512),\r\n            nn.ReLU(),\r\n            nn.Linear(512, feature_dim),\r\n            nn.ReLU()\r\n        )\r\n\r\n        # Classifier for source domain\r\n        self.classifier = nn.Sequential(\r\n            nn.Linear(feature_dim, 128),\r\n            nn.ReLU(),\r\n            nn.Linear(128, 64),\r\n            nn.ReLU(),\r\n            nn.Linear(64, 10)  # Number of classes\r\n        )\r\n\r\n        # Domain discriminator\r\n        self.domain_discriminator = nn.Sequential(\r\n            nn.Linear(feature_dim, 128),\r\n            nn.ReLU(),\r\n            nn.Linear(128, 64),\r\n            nn.ReLU(),\r\n            nn.Linear(64, 1)  # Binary classification: source vs target\r\n        )\r\n\r\n    def forward(self, x, domain_label=None):\r\n        features = self.feature_extractor(x)\r\n\r\n        # Classification output\r\n        class_output = self.classifier(features)\r\n\r\n        # Domain classification (only during training)\r\n        domain_output = None\r\n        if domain_label is not None:\r\n            domain_output = self.domain_discriminator(features)\r\n\r\n        return class_output, domain_output, features\r\n\r\nclass UnsupervisedDomainAdaptation:\r\n    def __init__(self, model, lr=1e-4):\r\n        self.model = model\r\n        self.classifier_criterion = nn.CrossEntropyLoss()\r\n        self.domain_criterion = nn.BCEWithLogitsLoss()\r\n\r\n        self.optimizer = optim.Adam(model.parameters(), lr=lr)\r\n        self.domain_optimizer = optim.Adam(model.parameters(), lr=lr)\r\n\r\n    def train_step(self, source_data, target_data, source_labels):\r\n        """Training step for domain adaptation"""\r\n        batch_size = source_data.size(0)\r\n\r\n        # Prepare domain labels\r\n        source_domain_labels = torch.zeros(batch_size, 1).to(source_data.device)\r\n        target_domain_labels = torch.ones(batch_size, 1).to(target_data.device)\r\n\r\n        # Train on source data\r\n        source_class_pred, source_domain_pred, _ = self.model(source_data, source_domain_labels)\r\n        source_class_loss = self.classifier_criterion(source_class_pred, source_labels)\r\n\r\n        # Train domain discriminator on source\r\n        source_domain_loss = self.domain_criterion(source_domain_pred, torch.zeros_like(source_domain_labels))\r\n\r\n        # Train on target data (unsupervised)\r\n        _, target_domain_pred, _ = self.model(target_data, target_domain_labels)\r\n        target_domain_loss = self.domain_criterion(target_domain_pred, torch.ones_like(target_domain_labels))\r\n\r\n        # Total loss for domain discriminator\r\n        domain_loss = source_domain_loss + target_domain_loss\r\n\r\n        # Gradient reversal for feature alignment\r\n        target_features = self.model.feature_extractor(target_data)\r\n        target_domain_pred_gr = self.model.domain_discriminator(target_features.detach())\r\n        domain_adversarial_loss = self.domain_criterion(target_domain_pred_gr, torch.zeros_like(target_domain_labels))\r\n\r\n        # Combined loss\r\n        total_loss = source_class_loss + 0.1 * domain_loss - 0.1 * domain_adversarial_loss\r\n\r\n        self.optimizer.zero_grad()\r\n        total_loss.backward()\r\n        self.optimizer.step()\r\n\r\n        return total_loss.item()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"simgan-simulation-to-reality-with-gans",children:"SimGAN (Simulation-to-Reality with GANs)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SimGAN(nn.Module):\r\n    def __init__(self, input_channels=3):\r\n        super(SimGAN, self).__init__()\r\n\r\n        # Refiner network (simulator \u2192 realistic)\r\n        self.refiner = nn.Sequential(\r\n            # Input: simulated image\r\n            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\r\n            nn.ReLU(),\r\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\r\n            nn.ReLU(),\r\n            nn.Conv2d(128, 64, kernel_size=3, padding=1),\r\n            nn.ReLU(),\r\n            nn.Conv2d(64, input_channels, kernel_size=3, padding=1),\r\n            nn.Tanh()\r\n        )\r\n\r\n        # Discriminator network\r\n        self.discriminator = nn.Sequential(\r\n            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),\r\n            nn.LeakyReLU(0.2),\r\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\r\n            nn.BatchNorm2d(128),\r\n            nn.LeakyReLU(0.2),\r\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\r\n            nn.BatchNorm2d(256),\r\n            nn.LeakyReLU(0.2),\r\n            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=0),\r\n            nn.Sigmoid()\r\n        )\r\n\r\n    def forward(self, sim_image):\r\n        refined_image = self.refiner(sim_image)\r\n        return refined_image\r\n\r\nclass SimGANTrainer:\r\n    def __init__(self, simgan_model, lr=2e-4):\r\n        self.model = simgan_model\r\n        self.optimizer_g = optim.Adam(self.model.refiner.parameters(), lr=lr)\r\n        self.optimizer_d = optim.Adam(self.model.discriminator.parameters(), lr=lr)\r\n        self.l1_loss = nn.L1Loss()\r\n        self.bce_loss = nn.BCELoss()\r\n\r\n    def train_step(self, real_images, sim_images):\r\n        """Training step for SimGAN"""\r\n        batch_size = sim_images.size(0)\r\n\r\n        # Labels for real/fake\r\n        real_labels = torch.ones(batch_size, 1, 1, 1).to(sim_images.device)\r\n        fake_labels = torch.zeros(batch_size, 1, 1, 1).to(sim_images.device)\r\n\r\n        # Train discriminator\r\n        self.optimizer_d.zero_grad()\r\n\r\n        # Real images\r\n        d_real = self.model.discriminator(real_images)\r\n        d_real_loss = self.bce_loss(d_real, real_labels)\r\n\r\n        # Simulated images (original)\r\n        d_sim = self.model.discriminator(sim_images)\r\n        d_sim_loss = self.bce_loss(d_sim, fake_labels)\r\n\r\n        # Refined images\r\n        refined_images = self.model(sim_images)\r\n        d_refined = self.model.discriminator(refined_images.detach())\r\n        d_refined_loss = self.bce_loss(d_refined, fake_labels)\r\n\r\n        d_loss = d_real_loss + d_sim_loss + d_refined_loss\r\n        d_loss.backward()\r\n        self.optimizer_d.step()\r\n\r\n        # Train generator (refiner)\r\n        self.optimizer_g.zero_grad()\r\n\r\n        # Adversarial loss\r\n        d_refined_for_g = self.model.discriminator(refined_images)\r\n        g_adv_loss = self.bce_loss(d_refined_for_g, real_labels)\r\n\r\n        # Content loss (preserve important features)\r\n        g_content_loss = self.l1_loss(refined_images, sim_images)\r\n\r\n        g_loss = g_adv_loss + 0.1 * g_content_loss\r\n        g_loss.backward()\r\n        self.optimizer_g.step()\r\n\r\n        return g_loss.item(), d_loss.item()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"system-identification-and-system-modeling",children:"System Identification and System Modeling"}),"\n",(0,i.jsx)(n.h3,{id:"system-identification-for-dynamics-matching",children:"System Identification for Dynamics Matching"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class SystemIdentifier:\r\n    def __init__(self, robot_model):\r\n        self.robot = robot_model\r\n        self.sim_params = {}\r\n        self.real_params = {}\r\n        self.correction_factors = {}\r\n\r\n    def identify_dynamics_parameters(self):\r\n        \"\"\"Identify key dynamics parameters\"\"\"\r\n        # Collect data from real robot\r\n        real_data = self.collect_real_robot_data()\r\n\r\n        # Estimate parameters using system identification\r\n        self.estimate_mass_parameters(real_data)\r\n        self.estimate_friction_parameters(real_data)\r\n        self.estimate_inertia_parameters(real_data)\r\n        self.estimate_actuator_dynamics(real_data)\r\n\r\n    def estimate_mass_parameters(self, data):\r\n        \"\"\"Estimate mass-related parameters\"\"\"\r\n        # Use least squares or other system identification methods\r\n        masses = []\r\n        for joint in self.robot.get_joints():\r\n            # Collect data for each joint\r\n            joint_data = self.filter_data_for_joint(data, joint.name)\r\n\r\n            # Estimate mass using inverse dynamics\r\n            estimated_mass = self.inverse_dynamics_mass_estimation(joint_data)\r\n            masses.append(estimated_mass)\r\n\r\n        self.real_params['masses'] = masses\r\n\r\n    def estimate_friction_parameters(self, data):\r\n        \"\"\"Estimate friction parameters (Coulomb and viscous)\"\"\"\r\n        friction_coeffs = []\r\n        for joint in self.robot.get_joints():\r\n            joint_data = self.filter_data_for_joint(data, joint.name)\r\n\r\n            # Estimate friction using regression\r\n            coulomb, viscous = self.estimate_friction_coefficients(joint_data)\r\n            friction_coeffs.append({'coulomb': coulomb, 'viscous': viscous})\r\n\r\n        self.real_params['friction'] = friction_coeffs\r\n\r\n    def collect_real_robot_data(self):\r\n        \"\"\"Collect experimental data from real robot\"\"\"\r\n        data = {\r\n            'joint_positions': [],\r\n            'joint_velocities': [],\r\n            'joint_accelerations': [],\r\n            'torques': [],\r\n            'timestamps': []\r\n        }\r\n\r\n        # Execute predefined trajectories\r\n        trajectories = self.generate_excitation_trajectories()\r\n\r\n        for traj in trajectories:\r\n            # Execute trajectory on real robot\r\n            self.execute_trajectory_safely(traj)\r\n\r\n            # Record data\r\n            recorded_data = self.record_robot_state()\r\n            data['joint_positions'].extend(recorded_data['positions'])\r\n            data['joint_velocities'].extend(recorded_data['velocities'])\r\n            data['torques'].extend(recorded_data['torques'])\r\n            data['timestamps'].extend(recorded_data['timestamps'])\r\n\r\n        return data\r\n\r\n    def update_simulation_with_real_params(self):\r\n        \"\"\"Update simulation with identified real-world parameters\"\"\"\r\n        for i, joint in enumerate(self.robot.get_joints()):\r\n            # Apply correction factors to simulation\r\n            if 'masses' in self.real_params:\r\n                real_mass = self.real_params['masses'][i]\r\n                sim_mass = joint.get_mass()\r\n                correction_factor = real_mass / sim_mass\r\n                joint.set_mass(real_mass)\r\n\r\n            if 'friction' in self.real_params:\r\n                real_friction = self.real_params['friction'][i]\r\n                joint.set_friction(real_friction['coulomb'], real_friction['viscous'])\n"})}),"\n",(0,i.jsx)(n.h2,{id:"adaptive-control-and-online-learning",children:"Adaptive Control and Online Learning"}),"\n",(0,i.jsx)(n.h3,{id:"online-domain-adaptation",children:"Online Domain Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class OnlineDomainAdapter:\r\n    def __init__(self, base_policy, adaptation_rate=0.01):\r\n        self.base_policy = base_policy\r\n        self.adaptation_rate = adaptation_rate\r\n        self.performance_history = []\r\n        self.adaptation_parameters = {}\r\n        self.is_adapting = True\r\n\r\n    def adapt_policy_online(self, real_observation, real_action, real_reward, sim_observation, sim_action):\r\n        \"\"\"Adapt policy based on real-world experience\"\"\"\r\n        if not self.is_adapting:\r\n            return\r\n\r\n        # Calculate performance difference\r\n        performance_diff = self.calculate_performance_difference(\r\n            real_observation, real_action, real_reward,\r\n            sim_observation, sim_action\r\n        )\r\n\r\n        # Update adaptation parameters\r\n        self.update_adaptation_parameters(performance_diff)\r\n\r\n        # Adjust policy based on adaptation\r\n        adapted_policy = self.apply_adaptation(self.base_policy, self.adaptation_parameters)\r\n\r\n        return adapted_policy\r\n\r\n    def calculate_performance_difference(self, real_obs, real_act, real_rew, sim_obs, sim_act):\r\n        \"\"\"Calculate the difference between real and simulated performance\"\"\"\r\n        # Calculate state difference\r\n        state_diff = np.linalg.norm(real_obs - sim_obs)\r\n\r\n        # Calculate action difference (if applicable)\r\n        action_diff = np.linalg.norm(real_act - sim_act) if sim_act is not None else 0\r\n\r\n        # Calculate reward difference\r\n        reward_diff = real_rew  # Real reward as indicator\r\n\r\n        return {\r\n            'state_diff': state_diff,\r\n            'action_diff': action_diff,\r\n            'reward_diff': reward_diff\r\n        }\r\n\r\n    def update_adaptation_parameters(self, performance_diff):\r\n        \"\"\"Update adaptation parameters based on performance\"\"\"\r\n        # Update based on state difference\r\n        if performance_diff['state_diff'] > 0.1:  # Threshold for significant difference\r\n            # Adjust observation preprocessing\r\n            self.adaptation_parameters['observation_scaling'] = self.adaptation_parameters.get('observation_scaling', 1.0) * (\r\n                1 - self.adaptation_rate * performance_diff['state_diff']\r\n            )\r\n\r\n        # Update based on reward difference\r\n        if performance_diff['reward_diff'] < 0:  # Negative reward indicates poor performance\r\n            # Increase exploration\r\n            self.adaptation_parameters['exploration_bonus'] = self.adaptation_parameters.get('exploration_bonus', 0.0) + (\r\n                self.adaptation_rate * abs(performance_diff['reward_diff'])\r\n            )\r\n\r\n    def apply_adaptation(self, base_policy, adaptation_params):\r\n        \"\"\"Apply adaptation to base policy\"\"\"\r\n        # This would typically involve adjusting policy parameters\r\n        # For example, modifying neural network weights or control gains\r\n        adapted_policy = base_policy.copy()\r\n\r\n        if 'observation_scaling' in adaptation_params:\r\n            adapted_policy.set_observation_scaling(adaptation_params['observation_scaling'])\r\n\r\n        if 'exploration_bonus' in adaptation_params:\r\n            adapted_policy.set_exploration_bonus(adaptation_params['exploration_bonus'])\r\n\r\n        return adapted_policy\n"})}),"\n",(0,i.jsx)(n.h2,{id:"sensor-fusion-and-calibration",children:"Sensor Fusion and Calibration"}),"\n",(0,i.jsx)(n.h3,{id:"multi-sensor-calibration-for-transfer",children:"Multi-Sensor Calibration for Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SensorCalibrator:\r\n    def __init__(self):\r\n        self.calibration_data = {}\r\n        self.transformation_matrices = {}\r\n        self.uncertainty_models = {}\r\n\r\n    def calibrate_camera_to_robot(self, camera, robot):\r\n        """Calibrate camera-to-robot transformation"""\r\n        # Collect calibration data using checkerboard or known objects\r\n        calibration_points = self.collect_calibration_data(camera, robot)\r\n\r\n        # Compute transformation matrix\r\n        transformation = self.compute_camera_robot_transform(calibration_points)\r\n\r\n        self.transformation_matrices[\'camera_to_robot\'] = transformation\r\n\r\n        # Estimate uncertainty\r\n        uncertainty = self.estimate_calibration_uncertainty(calibration_points)\r\n        self.uncertainty_models[\'camera_to_robot\'] = uncertainty\r\n\r\n    def collect_calibration_data(self, camera, robot):\r\n        """Collect calibration data points"""\r\n        calibration_points = []\r\n\r\n        # Move robot to known positions\r\n        calibration_poses = self.generate_calibration_poses()\r\n\r\n        for pose in calibration_poses:\r\n            # Move robot to calibration pose\r\n            robot.move_to_joint_position(pose)\r\n\r\n            # Capture image and extract features\r\n            image = camera.capture()\r\n            image_features = self.extract_features(image)\r\n\r\n            # Get robot\'s known position\r\n            robot_position = robot.get_end_effector_pose()\r\n\r\n            calibration_points.append({\r\n                \'image_features\': image_features,\r\n                \'robot_position\': robot_position\r\n            })\r\n\r\n        return calibration_points\r\n\r\n    def calibrate_lidar_to_camera(self, lidar, camera):\r\n        """Calibrate LiDAR to camera transformation"""\r\n        # Collect synchronized data\r\n        lidar_data, camera_data = self.collect_synchronized_data(lidar, camera)\r\n\r\n        # Find common features\r\n        common_features = self.match_features(lidar_data, camera_data)\r\n\r\n        # Compute transformation\r\n        transformation = self.compute_lidar_camera_transform(common_features)\r\n\r\n        self.transformation_matrices[\'lidar_to_camera\'] = transformation\r\n\r\n    def apply_sensor_correction(self, sensor_data, sensor_type):\r\n        """Apply calibration corrections to sensor data"""\r\n        corrected_data = sensor_data.copy()\r\n\r\n        if sensor_type == \'camera\':\r\n            # Apply camera intrinsics/extrinsics correction\r\n            corrected_data = self.correct_camera_data(sensor_data)\r\n\r\n        elif sensor_type == \'lidar\':\r\n            # Apply LiDAR calibration\r\n            corrected_data = self.correct_lidar_data(sensor_data)\r\n\r\n        elif sensor_type == \'imu\':\r\n            # Apply IMU bias and scale corrections\r\n            corrected_data = self.correct_imu_data(sensor_data)\r\n\r\n        return corrected_data\r\n\r\n    def correct_camera_data(self, camera_data):\r\n        """Apply camera calibration corrections"""\r\n        # Apply distortion correction\r\n        corrected_image = self.undistort_image(camera_data.image)\r\n\r\n        # Apply extrinsic transformation\r\n        corrected_pose = self.apply_transformation(\r\n            camera_data.pose,\r\n            self.transformation_matrices[\'camera_to_robot\']\r\n        )\r\n\r\n        return {\r\n            \'image\': corrected_image,\r\n            \'pose\': corrected_pose,\r\n            \'uncertainty\': self.uncertainty_models[\'camera_to_robot\']\r\n        }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"robust-control-techniques",children:"Robust Control Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"robust-control-for-domain-transfer",children:"Robust Control for Domain Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class RobustController:\r\n    def __init__(self, nominal_model, uncertainty_bounds):\r\n        self.nominal_model = nominal_model\r\n        self.uncertainty_bounds = uncertainty_bounds\r\n        self.controller = self.design_robust_controller()\r\n\r\n    def design_robust_controller(self):\r\n        """Design a robust controller that can handle uncertainties"""\r\n        # Use H-infinity or mu-synthesis techniques\r\n        # This is a simplified example - real implementation would be more complex\r\n\r\n        # Design controller with integral action for disturbance rejection\r\n        controller = {\r\n            \'Kp\': self.calculate_robust_proportional_gain(),\r\n            \'Ki\': self.calculate_robust_integral_gain(),\r\n            \'Kd\': self.calculate_robust_derivative_gain()\r\n        }\r\n\r\n        return controller\r\n\r\n    def calculate_robust_proportional_gain(self):\r\n        """Calculate proportional gain considering uncertainties"""\r\n        # Conservative gain selection based on uncertainty bounds\r\n        base_gain = self.nominal_model.calculate_nominal_gain()\r\n\r\n        # Reduce gain to ensure stability under uncertainties\r\n        robust_gain = base_gain * (1 - self.uncertainty_bounds[\'max_uncertainty\'])\r\n\r\n        return robust_gain\r\n\r\n    def apply_robust_control(self, state_error, uncertainty_estimate):\r\n        """Apply robust control law"""\r\n        # Use state error and uncertainty estimate to compute control\r\n        proportional_term = self.controller[\'Kp\'] * state_error\r\n\r\n        # Adjust for uncertainty\r\n        uncertainty_compensation = self.compensate_for_uncertainty(\r\n            uncertainty_estimate, state_error\r\n        )\r\n\r\n        control_output = proportional_term + uncertainty_compensation\r\n\r\n        # Apply safety limits\r\n        control_output = np.clip(control_output,\r\n                                -self.nominal_model.max_control,\r\n                                self.nominal_model.max_control)\r\n\r\n        return control_output\r\n\r\n    def compensate_for_uncertainty(self, uncertainty, error):\r\n        """Compensate control for model uncertainty"""\r\n        # Increase control effort based on uncertainty level\r\n        compensation_gain = uncertainty * self.controller[\'Kp\'] * 0.1\r\n\r\n        # Apply compensation in direction opposite to error\r\n        compensation = -compensation_gain * np.sign(error)\r\n\r\n        return compensation\n'})}),"\n",(0,i.jsx)(n.h2,{id:"transfer-learning-approaches",children:"Transfer Learning Approaches"}),"\n",(0,i.jsx)(n.h3,{id:"fine-tuning-for-real-world-deployment",children:"Fine-tuning for Real-World Deployment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class TransferLearner:\r\n    def __init__(self, pretrained_model, real_robot_data_size=100):\r\n        self.pretrained_model = pretrained_model\r\n        self.real_robot_data_size = real_robot_data_size\r\n        self.finetuning_phase = True\r\n\r\n    def finetune_on_real_data(self, real_data_loader):\r\n        """Fine-tune pretrained model on real robot data"""\r\n        # Freeze early layers, fine-tune later layers\r\n        self.freeze_early_layers()\r\n\r\n        # Define fine-tuning optimizer (lower learning rate)\r\n        optimizer = optim.Adam(\r\n            filter(lambda p: p.requires_grad, self.pretrained_model.parameters()),\r\n            lr=1e-5  # Lower learning rate for fine-tuning\r\n        )\r\n\r\n        criterion = nn.MSELoss()\r\n\r\n        for epoch in range(10):  # Limited epochs to prevent overfitting\r\n            for batch_idx, (data, target) in enumerate(real_data_loader):\r\n                optimizer.zero_grad()\r\n                output = self.pretrained_model(data)\r\n                loss = criterion(output, target)\r\n                loss.backward()\r\n                optimizer.step()\r\n\r\n                if batch_idx % 10 == 0:\r\n                    print(f\'Fine-tuning Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.6f}\')\r\n\r\n    def freeze_early_layers(self):\r\n        """Freeze early layers of the network"""\r\n        # Example: freeze first half of the layers\r\n        layers = list(self.pretrained_model.children())\r\n        num_layers_to_freeze = len(layers) // 2\r\n\r\n        for i in range(num_layers_to_freeze):\r\n            for param in layers[i].parameters():\r\n                param.requires_grad = False\r\n\r\n    def gradual_unfreezing(self, real_data_loader):\r\n        """Gradually unfreeze layers during fine-tuning"""\r\n        layers = list(self.pretrained_model.children())\r\n        num_layers = len(layers)\r\n\r\n        for layer_idx in range(num_layers):\r\n            # Unfreeze current layer\r\n            for param in layers[layer_idx].parameters():\r\n                param.requires_grad = True\r\n\r\n            # Fine-tune with current unfrozen layers\r\n            self.finetune_current_setup(real_data_loader, layer_idx)\r\n\r\n    def finetune_current_setup(self, data_loader, layer_idx):\r\n        """Fine-tune with current layer setup"""\r\n        optimizer = optim.Adam(\r\n            filter(lambda p: p.requires_grad, self.pretrained_model.parameters()),\r\n            lr=1e-5 * (layer_idx + 1)  # Slightly increase learning rate\r\n        )\r\n\r\n        # Run few epochs with current setup\r\n        for epoch in range(3):\r\n            total_loss = 0\r\n            for data, target in data_loader:\r\n                optimizer.zero_grad()\r\n                output = self.pretrained_model(data)\r\n                loss = nn.MSELoss()(output, target)\r\n                loss.backward()\r\n                optimizer.step()\r\n                total_loss += loss.item()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"validation-and-testing-strategies",children:"Validation and Testing Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"sim-to-real-validation-framework",children:"Sim-to-Real Validation Framework"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SimToRealValidator:\r\n    def __init__(self, sim_env, real_env):\r\n        self.sim_env = sim_env\r\n        self.real_env = real_env\r\n        self.metrics = {\r\n            \'success_rate\': [],\r\n            \'execution_time\': [],\r\n            \'trajectory_deviation\': [],\r\n            \'energy_efficiency\': []\r\n        }\r\n\r\n    def validate_transfer(self, policy, num_trials=10):\r\n        """Validate policy transfer from sim to real"""\r\n        sim_successes = 0\r\n        real_successes = 0\r\n\r\n        for trial in range(num_trials):\r\n            # Test in simulation\r\n            sim_success, sim_time, sim_trajectory = self.test_in_simulation(policy)\r\n            sim_successes += sim_success\r\n\r\n            # Test on real robot\r\n            real_success, real_time, real_trajectory = self.test_on_real_robot(policy)\r\n            real_successes += real_success\r\n\r\n            # Calculate trajectory deviation\r\n            deviation = self.calculate_trajectory_deviation(sim_trajectory, real_trajectory)\r\n\r\n            # Record metrics\r\n            self.metrics[\'success_rate\'].append((sim_success, real_success))\r\n            self.metrics[\'execution_time\'].append((sim_time, real_time))\r\n            self.metrics[\'trajectory_deviation\'].append(deviation)\r\n\r\n        # Calculate transfer success rate\r\n        sim_success_rate = sim_successes / num_trials\r\n        real_success_rate = real_successes / num_trials\r\n\r\n        transfer_success_rate = real_success_rate / sim_success_rate if sim_success_rate > 0 else 0\r\n\r\n        return {\r\n            \'sim_success_rate\': sim_success_rate,\r\n            \'real_success_rate\': real_success_rate,\r\n            \'transfer_success_rate\': transfer_success_rate,\r\n            \'average_deviation\': np.mean(self.metrics[\'trajectory_deviation\'])\r\n        }\r\n\r\n    def calculate_trajectory_deviation(self, sim_traj, real_traj):\r\n        """Calculate deviation between simulated and real trajectories"""\r\n        if len(sim_traj) == 0 or len(real_traj) == 0:\r\n            return float(\'inf\')\r\n\r\n        # Interpolate trajectories to same length\r\n        sim_interp = self.interpolate_trajectory(sim_traj, 100)\r\n        real_interp = self.interpolate_trajectory(real_traj, 100)\r\n\r\n        # Calculate average distance between trajectories\r\n        distances = []\r\n        for s, r in zip(sim_interp, real_interp):\r\n            dist = np.linalg.norm(np.array(s) - np.array(r))\r\n            distances.append(dist)\r\n\r\n        return np.mean(distances)\r\n\r\n    def test_in_simulation(self, policy):\r\n        """Test policy in simulation environment"""\r\n        state = self.sim_env.reset()\r\n        trajectory = []\r\n        success = False\r\n        start_time = time.time()\r\n\r\n        for step in range(1000):  # Max steps\r\n            action = policy.select_action(state)\r\n            next_state, reward, done, info = self.sim_env.step(action)\r\n\r\n            trajectory.append(next_state)\r\n\r\n            if self.is_task_success(next_state):\r\n                success = True\r\n                break\r\n\r\n            if done:\r\n                break\r\n\r\n            state = next_state\r\n\r\n        execution_time = time.time() - start_time\r\n        return success, execution_time, trajectory\r\n\r\n    def test_on_real_robot(self, policy):\r\n        """Test policy on real robot (with safety measures)"""\r\n        # Reset real robot to safe state\r\n        self.reset_real_robot_safely()\r\n\r\n        state = self.get_real_robot_state()\r\n        trajectory = []\r\n        success = False\r\n        start_time = time.time()\r\n\r\n        for step in range(1000):  # Max steps\r\n            # Add safety checks\r\n            if self.is_robot_in_safe_state():\r\n                action = policy.select_action(state)\r\n                next_state, reward, done, info = self.execute_real_action(action)\r\n\r\n                trajectory.append(next_state)\r\n\r\n                if self.is_task_success_real(next_state):\r\n                    success = True\r\n                    break\r\n\r\n                if done or self.is_emergency_stop_needed():\r\n                    break\r\n\r\n                state = next_state\r\n            else:\r\n                # Emergency stop\r\n                self.emergency_stop()\r\n                break\r\n\r\n        execution_time = time.time() - start_time\r\n        return success, execution_time, trajectory\r\n\r\n    def is_robot_in_safe_state(self):\r\n        """Check if robot is in safe operational state"""\r\n        # Check joint limits, collisions, etc.\r\n        joint_positions = self.get_real_robot_joint_positions()\r\n        joint_limits = self.get_robot_joint_limits()\r\n\r\n        for pos, limits in zip(joint_positions, joint_limits):\r\n            if pos < limits[0] or pos > limits[1]:\r\n                return False\r\n\r\n        # Check for collisions\r\n        if self.detect_real_robot_collision():\r\n            return False\r\n\r\n        return True\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-successful-transfer",children:"Best Practices for Successful Transfer"}),"\n",(0,i.jsx)(n.h3,{id:"1-gradual-deployment-strategy",children:"1. Gradual Deployment Strategy"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class GradualDeployment:\r\n    def __init__(self, policy, safety_monitor):\r\n        self.policy = policy\r\n        self.safety_monitor = safety_monitor\r\n        self.confidence_levels = [\'low\', \'medium\', \'high\']\r\n        self.current_confidence = \'low\'\r\n\r\n    def deploy_gradually(self):\r\n        """Deploy policy with increasing confidence levels"""\r\n        for confidence in self.confidence_levels:\r\n            print(f"Deploying at {confidence} confidence level")\r\n\r\n            if self.test_at_confidence_level(confidence):\r\n                self.current_confidence = confidence\r\n                print(f"Success at {confidence} level, proceeding to next")\r\n            else:\r\n                print(f"Failed at {confidence} level, stopping deployment")\r\n                break\r\n\r\n    def test_at_confidence_level(self, confidence):\r\n        """Test policy at specific confidence level"""\r\n        if confidence == \'low\':\r\n            # Limited workspace, simple tasks\r\n            return self.test_simple_task()\r\n        elif confidence == \'medium\':\r\n            # Extended workspace, moderate complexity\r\n            return self.test_moderate_task()\r\n        elif confidence == \'high\':\r\n            # Full workspace, complex tasks\r\n            return self.test_complex_task()\r\n\r\n    def test_simple_task(self):\r\n        """Test on simple, safe tasks"""\r\n        # Use only safe, well-tested parts of policy\r\n        return self.safety_monitor.run_safety_test(self.policy, \'simple\')\r\n\r\n    def test_moderate_task(self):\r\n        """Test on moderate complexity tasks"""\r\n        return self.safety_monitor.run_safety_test(self.policy, \'moderate\')\r\n\r\n    def test_complex_task(self):\r\n        """Test on complex tasks"""\r\n        return self.safety_monitor.run_safety_test(self.policy, \'complex\')\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-safety-first-approach",children:"2. Safety-First Approach"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SafetyFirstTransfer:\r\n    def __init__(self, robot_controller):\r\n        self.controller = robot_controller\r\n        self.safety_limits = self.define_safety_limits()\r\n        self.emergency_procedures = self.define_emergency_procedures()\r\n\r\n    def define_safety_limits(self):\r\n        """Define comprehensive safety limits"""\r\n        return {\r\n            \'velocity_limits\': [0.5, 0.5, 0.5, 1.0, 1.0, 1.0],  # Cartesian + joint limits\r\n            \'force_limits\': [50, 50, 50, 5, 5, 5],  # Force limits in each direction\r\n            \'workspace_limits\': {\r\n                \'min\': [-1.0, -1.0, 0.0],\r\n                \'max\': [1.0, 1.0, 2.0]\r\n            },\r\n            \'collision_threshold\': 0.1  # Minimum distance to obstacles\r\n        }\r\n\r\n    def execute_with_safety(self, planned_action):\r\n        """Execute action with safety checks"""\r\n        # Check velocity limits\r\n        if not self.check_velocity_limits(planned_action):\r\n            return self.get_safe_action()\r\n\r\n        # Check force limits\r\n        if not self.check_force_limits():\r\n            return self.get_safe_action()\r\n\r\n        # Check workspace limits\r\n        if not self.check_workspace_limits(planned_action):\r\n            return self.get_safe_action()\r\n\r\n        # Check for potential collisions\r\n        if not self.check_collision_safety(planned_action):\r\n            return self.get_safe_action()\r\n\r\n        # If all checks pass, execute planned action\r\n        return planned_action\r\n\r\n    def check_velocity_limits(self, action):\r\n        """Check if action violates velocity limits"""\r\n        velocities = self.controller.calculate_velocities_from_action(action)\r\n        for vel, limit in zip(velocities, self.safety_limits[\'velocity_limits\']):\r\n            if abs(vel) > limit:\r\n                return False\r\n        return True\r\n\r\n    def check_collision_safety(self, action):\r\n        """Check if action might cause collision"""\r\n        future_positions = self.controller.predict_future_positions(action)\r\n\r\n        for pos in future_positions:\r\n            if self.is_position_in_collision(pos):\r\n                return False\r\n        return True\r\n\r\n    def get_safe_action(self):\r\n        """Return safe action when checks fail"""\r\n        # Return action that brings robot to safe state\r\n        return self.controller.get_stop_action()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting-common-transfer-issues",children:"Troubleshooting Common Transfer Issues"}),"\n",(0,i.jsx)(n.h3,{id:"1-performance-degradation",children:"1. Performance Degradation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def diagnose_performance_degradation():\r\n    """Diagnose common causes of performance degradation"""\r\n    issues = []\r\n\r\n    # Check for sensor calibration drift\r\n    if sensor_calibration_drifted():\r\n        issues.append("Sensor calibration has drifted - recalibrate sensors")\r\n\r\n    # Check for actuator wear\r\n    if actuator_performance_degraded():\r\n        issues.append("Actuators may be worn - check mechanical components")\r\n\r\n    # Check for environmental changes\r\n    if environment_changed():\r\n        issues.append("Environment has changed - update simulation or adapt policy")\r\n\r\n    # Check for timing differences\r\n    if timing_mismatch():\r\n        issues.append("Timing mismatch between sim and real - synchronize control loops")\r\n\r\n    return issues\r\n\r\ndef sensor_calibration_drifted():\r\n    """Check if sensor calibration has drifted"""\r\n    # Compare current sensor readings with known reference\r\n    return False  # Implementation depends on specific sensors\r\n\r\ndef actuator_performance_degraded():\r\n    """Check if actuators have degraded"""\r\n    # Compare current performance with baseline\r\n    return False\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-instability-and-oscillation",children:"2. Instability and Oscillation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def stabilize_unstable_system():\r\n    """Methods to stabilize unstable transferred system"""\r\n    # Reduce control gains\r\n    reduce_control_gains()\r\n\r\n    # Add damping\r\n    increase_damping()\r\n\r\n    # Lower control frequency\r\n    reduce_control_frequency()\r\n\r\n    # Add low-pass filtering\r\n    apply_low_pass_filtering()\r\n\r\ndef reduce_control_gains():\r\n    """Reduce control gains to improve stability"""\r\n    # Apply conservative gain scheduling\r\n    current_gains = get_current_gains()\r\n    new_gains = [g * 0.8 for g in current_gains]  # Reduce by 20%\r\n    set_control_gains(new_gains)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"Sim-to-Real transfer is a critical challenge in robotics that requires careful consideration of multiple factors including visual domain differences, physics modeling, sensor calibration, and control robustness. Success depends on:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Proper Domain Randomization"}),": Creating diverse simulation environments that encompass real-world variations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"System Identification"}),": Accurately modeling real-world dynamics and characteristics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robust Control"}),": Designing controllers that can handle uncertainties and disturbances"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gradual Deployment"}),": Carefully testing and validating policies with increasing complexity"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety-First Approach"}),": Implementing comprehensive safety measures and emergency procedures"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The NVIDIA Isaac Platform provides excellent tools for sim-to-real transfer including Isaac Sim for high-fidelity simulation, Isaac ROS for real-world integration, and comprehensive calibration and validation tools. By following best practices and using appropriate techniques, complex robotic policies can be successfully transferred from simulation to real-world deployment."}),"\n",(0,i.jsx)(n.p,{children:"In the next section, we'll create a practical lab exercise to apply these sim-to-real transfer concepts."})]})}function _(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var a=r(6540);const i={},t=a.createContext(i);function s(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);