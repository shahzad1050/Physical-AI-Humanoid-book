"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[7207],{3416:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>_,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module4/dynamics-control","title":"Dynamics and Control","description":"Introduction to Humanoid Robot Dynamics","source":"@site/docs/module4/dynamics-control.md","sourceDirName":"module4","slug":"/module4/dynamics-control","permalink":"/Physical-AI-Humanoid-book/docs/module4/dynamics-control","draft":false,"unlisted":false,"editUrl":"https://github.com/user/physical-ai-humanoid-robotics/tree/main/docs/module4/dynamics-control.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 4 Conclusion: Humanoid Robot Development","permalink":"/Physical-AI-Humanoid-book/docs/module4/conclusion"},"next":{"title":"Human-Robot Interaction","permalink":"/Physical-AI-Humanoid-book/docs/module4/human-robot-interaction"}}');var i=t(4848),r=t(8453);const a={},s="Dynamics and Control",l={},c=[{value:"Introduction to Humanoid Robot Dynamics",id:"introduction-to-humanoid-robot-dynamics",level:2},{value:"Mathematical Foundations of Dynamics",id:"mathematical-foundations-of-dynamics",level:2},{value:"Newton-Euler Formulation",id:"newton-euler-formulation",level:3},{value:"Lagrangian Formulation",id:"lagrangian-formulation",level:3},{value:"Generalized Equation of Motion",id:"generalized-equation-of-motion",level:3},{value:"Derivation of Humanoid Dynamics",id:"derivation-of-humanoid-dynamics",level:2},{value:"Mass Matrix (M(q))",id:"mass-matrix-mq",level:3},{value:"Coriolis and Centrifugal Matrix (C(q,q\u0307))",id:"coriolis-and-centrifugal-matrix-cqq\u0307",level:3},{value:"Gravity Vector (g(q))",id:"gravity-vector-gq",level:3},{value:"Control Methods for Humanoid Robots",id:"control-methods-for-humanoid-robots",level:2},{value:"Computed Torque Control (Inverse Dynamics Control)",id:"computed-torque-control-inverse-dynamics-control",level:3},{value:"Operational Space Control",id:"operational-space-control",level:3},{value:"Impedance Control",id:"impedance-control",level:3},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:2},{value:"Zero Moment Point (ZMP) Based Control",id:"zero-moment-point-zmp-based-control",level:3},{value:"Preview Control",id:"preview-control",level:3},{value:"Balance Control",id:"balance-control",level:2},{value:"Linear Inverted Pendulum Model (LIPM)",id:"linear-inverted-pendulum-model-lipm",level:3},{value:"Whole-Body Control",id:"whole-body-control",level:3},{value:"Control Implementation Example",id:"control-implementation-example",level:2},{value:"Advanced Control Techniques",id:"advanced-control-techniques",level:2},{value:"Model Predictive Control (MPC)",id:"model-predictive-control-mpc",level:3},{value:"Control Architecture",id:"control-architecture",level:2},{value:"Hierarchical Control Structure",id:"hierarchical-control-structure",level:3},{value:"Simulation and Testing",id:"simulation-and-testing",level:2},{value:"Simulation Environment",id:"simulation-environment",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"dynamics-and-control",children:"Dynamics and Control"})}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-humanoid-robot-dynamics",children:"Introduction to Humanoid Robot Dynamics"}),"\n",(0,i.jsx)(e.p,{children:"Dynamics in humanoid robotics deals with the forces and torques that cause motion, as opposed to kinematics which only describes motion. For humanoid robots, dynamics is crucial for understanding how the robot responds to control inputs, external forces, and environmental interactions. Proper dynamic modeling and control are essential for stable walking, manipulation, and interaction with the environment."}),"\n",(0,i.jsx)(e.h2,{id:"mathematical-foundations-of-dynamics",children:"Mathematical Foundations of Dynamics"}),"\n",(0,i.jsx)(e.h3,{id:"newton-euler-formulation",children:"Newton-Euler Formulation"}),"\n",(0,i.jsx)(e.p,{children:"The Newton-Euler equations form the basis for rigid body dynamics:"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Translational motion:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"F = ma\n"})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Rotational motion:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"\u03c4 = I\u03b1 + \u03c9 \xd7 (I\u03c9)\n"})}),"\n",(0,i.jsx)(e.p,{children:"Where:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"F"})," is the force vector"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"m"})," is the mass"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"a"})," is the linear acceleration"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"\u03c4"})," is the torque vector"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"I"})," is the inertia tensor"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"\u03b1"})," is the angular acceleration"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"\u03c9"})," is the angular velocity"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"lagrangian-formulation",children:"Lagrangian Formulation"}),"\n",(0,i.jsx)(e.p,{children:"For complex multi-body systems like humanoid robots, the Lagrangian formulation is often more convenient:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"L = T - V\n"})}),"\n",(0,i.jsx)(e.p,{children:"Where:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"L"})," is the Lagrangian"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"T"})," is the kinetic energy"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"V"})," is the potential energy"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The equations of motion are given by the Euler-Lagrange equations:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"d/dt(\u2202L/\u2202q\u0307) - \u2202L/\u2202q = \u03c4\n"})}),"\n",(0,i.jsx)(e.p,{children:"Where:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"q"})," is the vector of generalized coordinates (joint angles)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"q\u0307"})," is the vector of generalized velocities (joint velocities)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"\u03c4"})," is the vector of generalized forces (joint torques)"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"generalized-equation-of-motion",children:"Generalized Equation of Motion"}),"\n",(0,i.jsxs)(e.p,{children:["For a humanoid robot with ",(0,i.jsx)(e.code,{children:"n"})," degrees of freedom, the equation of motion can be written as:"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"M(q)q\u0308 + C(q,q\u0307)q\u0307 + g(q) = \u03c4 + J^T(q)F_ext\n"})}),"\n",(0,i.jsx)(e.p,{children:"Where:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"M(q)"})," is the mass/inertia matrix"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"C(q,q\u0307)"})," is the Coriolis and centrifugal matrix"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"g(q)"})," is the gravity vector"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"\u03c4"})," is the vector of joint torques"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"J(q)"})," is the Jacobian matrix"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"F_ext"})," is the vector of external forces"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"derivation-of-humanoid-dynamics",children:"Derivation of Humanoid Dynamics"}),"\n",(0,i.jsx)(e.h3,{id:"mass-matrix-mq",children:"Mass Matrix (M(q))"}),"\n",(0,i.jsx)(e.p,{children:"The mass matrix represents the inertial properties of the robot:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef calculate_mass_matrix(robot_kinematics, joint_angles, link_masses, link_inertias):\n    """\n    Calculate mass matrix using the Composite Rigid Body Algorithm (CRBA)\n    """\n    n = len(joint_angles)\n    M = np.zeros((n, n))\n\n    # Calculate transforms for each link\n    transforms = []\n    for i in range(n):\n        # Calculate transform from base to link i\n        T = robot_kinematics.forward_kinematics_partial(joint_angles[:i+1], i)\n        transforms.append(T)\n\n    # For each pair of joints, calculate their inertial coupling\n    for i in range(n):\n        for j in range(i, n):\n            # Calculate the spatial inertia of the subtree from joint j\n            subtree_inertia = calculate_subtree_inertia(j, transforms, link_masses, link_inertias)\n\n            # Calculate the Jacobian for joint i\n            Ji = calculate_jacobian_link(robot_kinematics, joint_angles, i)\n\n            # Calculate the Jacobian for joint j\n            Jj = calculate_jacobian_link(robot_kinematics, joint_angles, j)\n\n            # Calculate the coupling term\n            M[i, j] = Ji.T @ subtree_inertia @ Jj\n\n            # Matrix is symmetric\n            if i != j:\n                M[j, i] = M[i, j]\n\n    return M\n\ndef calculate_subtree_inertia(link_idx, transforms, link_masses, link_inertias):\n    """\n    Calculate the composite inertia of a subtree starting from link_idx\n    """\n    # This is a simplified version - full implementation would be more complex\n    total_inertia = np.zeros((6, 6))  # Spatial inertia (3 linear + 3 angular)\n\n    # Add inertia of the link itself\n    link_transform = transforms[link_idx]\n    link_inertia_6d = spatial_inertia(link_masses[link_idx], link_inertias[link_idx], link_transform)\n\n    total_inertia += link_inertia_6d\n\n    # Add inertias of all child links (simplified)\n    # In a full implementation, this would recursively include all descendant links\n\n    return total_inertia\n\ndef spatial_inertia(mass, inertia_3d, transform):\n    """\n    Convert 3D inertia to 6D spatial inertia at a given transform\n    """\n    # Extract rotation and translation from transform\n    R = transform[:3, :3]\n    p = transform[:3, 3]\n\n    # Convert 3D inertia to spatial inertia\n    # This is a simplified representation\n    spatial_I = np.zeros((6, 6))\n\n    # Mass term\n    spatial_I[0:3, 0:3] = mass * np.eye(3)\n\n    # Inertia term\n    I_rotated = R @ inertia_3d @ R.T\n    spatial_I[3:6, 3:6] = I_rotated\n\n    return spatial_I\n'})}),"\n",(0,i.jsx)(e.h3,{id:"coriolis-and-centrifugal-matrix-cqq\u0307",children:"Coriolis and Centrifugal Matrix (C(q,q\u0307))"}),"\n",(0,i.jsx)(e.p,{children:"The Coriolis and centrifugal forces arise from velocity-dependent terms:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def calculate_coriolis_matrix(robot_kinematics, joint_angles, joint_velocities, link_masses):\n    """\n    Calculate Coriolis and centrifugal matrix\n    """\n    n = len(joint_angles)\n    C = np.zeros((n, n))\n\n    # Use Christoffel symbols of the first kind\n    M = calculate_mass_matrix(robot_kinematics, joint_angles, link_masses,\n                              [np.eye(3) for _ in link_masses])  # Simplified inertia\n\n    for i in range(n):\n        for j in range(n):\n            c_sum = 0\n            for k in range(n):\n                # Christoffel symbol: \u0393^i_jk = 0.5 * (\u2202M_ik/\u2202q_j + \u2202M_jk/\u2202q_i - \u2202M_ij/\u2202q_k)\n                gamma = 0.5 * (partial_derivative_M(M, i, k, j, joint_angles) +\n                              partial_derivative_M(M, j, k, i, joint_angles) -\n                              partial_derivative_M(M, i, j, k, joint_angles))\n                c_sum += gamma * joint_velocities[k]\n            C[i, j] = c_sum\n\n    return C\n\ndef partial_derivative_M(M, i, j, k, joint_angles, h=1e-6):\n    """\n    Numerical approximation of partial derivative of mass matrix\n    """\n    # This is a simplified placeholder - in practice, analytical derivatives are preferred\n    angles_plus = joint_angles.copy()\n    angles_plus[k] += h\n    M_plus = calculate_mass_matrix_partial(angles_plus)  # Simplified function\n\n    angles_minus = joint_angles.copy()\n    angles_minus[k] -= h\n    M_minus = calculate_mass_matrix_partial(angles_minus)  # Simplified function\n\n    return (M_plus[i, j] - M_minus[i, j]) / (2 * h)\n'})}),"\n",(0,i.jsx)(e.h3,{id:"gravity-vector-gq",children:"Gravity Vector (g(q))"}),"\n",(0,i.jsx)(e.p,{children:"The gravity vector accounts for gravitational forces acting on each link:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def calculate_gravity_vector(robot_kinematics, joint_angles, link_masses, gravity=[0, 0, -9.81]):\n    """\n    Calculate gravity vector for the robot\n    """\n    n = len(joint_angles)\n    g = np.zeros(n)\n\n    gravity_vec = np.array(gravity)\n\n    for i in range(n):\n        # Calculate Jacobian for link i\n        Ji = calculate_jacobian_link(robot_kinematics, joint_angles, i)\n\n        # Calculate position of link i\'s center of mass\n        pos_com = calculate_link_com_position(robot_kinematics, joint_angles, i)\n\n        # Calculate gravitational force on this link\n        F_gravity = link_masses[i] * gravity_vec\n\n        # Project gravitational force onto joint i\n        g[i] = Ji[:3, i].T @ F_gravity  # Only linear part affects joint torque\n\n    return g\n\ndef calculate_link_com_position(robot_kinematics, joint_angles, link_idx):\n    """\n    Calculate the position of the center of mass of a link\n    """\n    # This would use forward kinematics to find link COM position\n    T = robot_kinematics.forward_kinematics_partial(joint_angles[:link_idx+1], link_idx)\n    # Add offset from joint to COM\n    com_offset = np.array([0, 0, 0])  # Simplified - would come from URDF\n    return T[:3, 3] + T[:3, :3] @ com_offset\n'})}),"\n",(0,i.jsx)(e.h2,{id:"control-methods-for-humanoid-robots",children:"Control Methods for Humanoid Robots"}),"\n",(0,i.jsx)(e.h3,{id:"computed-torque-control-inverse-dynamics-control",children:"Computed Torque Control (Inverse Dynamics Control)"}),"\n",(0,i.jsx)(e.p,{children:"Computed torque control linearizes the robot dynamics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class ComputedTorqueController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.Kp = np.diag([100, 100, 100, 50, 50, 50])  # Proportional gains\n        self.Kd = np.diag([20, 20, 20, 10, 10, 10])     # Derivative gains\n\n    def compute_control_torque(self, q, qd, q_desired, qd_desired, qdd_desired):\n        """\n        Compute control torque using computed torque method\n        """\n        # Calculate current dynamics\n        M = self.model.mass_matrix(q)\n        C = self.model.coriolis_matrix(q, qd)\n        g = self.model.gravity_vector(q)\n\n        # Calculate control law\n        # \u03c4 = M(q) * (qdd_d + Kd*(qd_d - qd) + Kp*(q_d - q)) + C(q,qd)*qd + g(q)\n        tracking_error = q_desired - q\n        velocity_error = qd_desired - qd\n\n        feedforward_term = M @ qdd_desired\n        feedback_term = M @ (self.Kd @ velocity_error + self.Kp @ tracking_error)\n        coriolis_gravity_term = C @ qd + g\n\n        tau = feedforward_term + feedback_term + coriolis_gravity_term\n\n        return tau\n'})}),"\n",(0,i.jsx)(e.h3,{id:"operational-space-control",children:"Operational Space Control"}),"\n",(0,i.jsx)(e.p,{children:"Operational space control allows control in task space (end-effector space):"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class OperationalSpaceController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n\n    def compute_task_space_control(self, q, qd, x_desired, xd_desired, xdd_desired,\n                                   task_jacobian, task_inertia):\n        """\n        Compute control in operational space\n        """\n        # Calculate joint-space mass matrix\n        M = self.model.mass_matrix(q)\n\n        # Calculate operational space inertia\n        # Lambda = (J * M^(-1) * J^T)^(-1)\n        J = task_jacobian\n        Lambda = np.linalg.inv(J @ np.linalg.inv(M) @ J.T)\n\n        # Calculate operational space Coriolis and gravity terms\n        # This is simplified - full implementation is more complex\n        h_op = self.calculate_operational_coriolis_gravity(q, qd, J, M)\n\n        # Calculate operational space error\n        x_error = x_desired - self.get_current_task_position(q)\n        xd_error = xd_desired - self.get_current_task_velocity(q, qd)\n\n        # Control law in operational space\n        # F_task = Lambda * (xdd_d + Kd*xd_error + Kp*x_error) + h_op\n        Kp = 100 * np.eye(len(x_desired))  # Position gains\n        Kd = 20 * np.eye(len(x_desired))   # Velocity gains\n\n        F_task = (Lambda @ (xdd_desired + Kd @ xd_error + Kp @ x_error) + h_op)\n\n        # Convert to joint torques\n        # \u03c4 = J^T * F_task + N^T * \u03c4_null\n        # where N is the null space projector\n        tau = J.T @ F_task\n\n        # Add null space motion to avoid joint limits\n        tau += self.compute_null_space_motion(q, qd, M, J)\n\n        return tau\n\n    def calculate_operational_coriolis_gravity(self, q, qd, J, M):\n        """\n        Calculate Coriolis and gravity terms in operational space\n        """\n        # This is a simplified representation\n        # Full implementation requires careful calculation of dJ/dt\n        return np.zeros(len(J))\n\n    def compute_null_space_motion(self, q, qd, M, J):\n        """\n        Compute motion in null space to achieve secondary objectives\n        """\n        # Null space projector: N = I - M^(-1) * J^T * Lambda * J\n        Lambda = np.linalg.inv(J @ np.linalg.inv(M) @ J.T)\n        N = np.eye(len(q)) - np.linalg.inv(M) @ J.T @ Lambda @ J\n\n        # Desired null space motion (e.g., toward joint centers)\n        q_center = np.zeros(len(q))  # Joint center positions\n        K_null = 1.0  # Null space gain\n        q_null_desired = K_null * (q_center - q)\n\n        # Apply null space motion\n        tau_null = N.T @ q_null_desired\n\n        return tau_null\n'})}),"\n",(0,i.jsx)(e.h3,{id:"impedance-control",children:"Impedance Control"}),"\n",(0,i.jsx)(e.p,{children:"Impedance control makes the robot behave like a mechanical system with desired stiffness, damping, and inertia:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class ImpedanceController:\n    def __init__(self, desired_mass, desired_damping, desired_stiffness):\n        self.M_d = desired_mass      # Desired inertia\n        self.D_d = desired_damping   # Desired damping\n        self.K_d = desired_stiffness # Desired stiffness\n\n    def compute_impedance_control(self, x, xd, x_desired, xd_desired, xdd_desired,\n                                  jacobian, mass_matrix):\n        """\n        Compute impedance control law\n        """\n        # Calculate position and velocity errors\n        x_error = x_desired - x\n        xd_error = xd_desired - xd\n\n        # Impedance control law in task space\n        # M_d * (xdd_d - xdd) + D_d * (xd_d - xd) + K_d * (x_d - x) = F_ext\n        F_impedance = (self.M_d @ (xdd_desired - self.calculate_xdd(x, xd)) +\n                      self.D_d @ xd_error +\n                      self.K_d @ x_error)\n\n        # Convert to joint space\n        tau = jacobian.T @ F_impedance\n\n        return tau\n\n    def calculate_xdd(self, x, xd, dt=0.01):\n        """\n        Calculate acceleration from position and velocity\n        """\n        # This would use numerical differentiation or state estimation\n        return np.zeros_like(x)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"walking-pattern-generation",children:"Walking Pattern Generation"}),"\n",(0,i.jsx)(e.h3,{id:"zero-moment-point-zmp-based-control",children:"Zero Moment Point (ZMP) Based Control"}),"\n",(0,i.jsx)(e.p,{children:"ZMP is crucial for stable bipedal walking:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class ZMPController:\n    def __init__(self, robot_height, gravity=9.81):\n        self.h = robot_height  # Height of center of mass\n        self.g = gravity\n\n    def calculate_zmp_from_com(self, com_pos, com_vel, com_acc):\n        """\n        Calculate ZMP from center of mass trajectory\n        """\n        x_com, y_com = com_pos[:2]\n        x_com_dot, y_com_dot = com_vel[:2]\n        x_com_ddot, y_com_ddot = com_acc[:2]\n\n        # ZMP equations (simplified for 2D)\n        zmp_x = x_com - (self.h / self.g) * x_com_ddot\n        zmp_y = y_com - (self.h / self.g) * y_com_ddot\n\n        return np.array([zmp_x, zmp_y, 0])\n\n    def generate_com_trajectory(self, zmp_trajectory, initial_com, duration, dt=0.01):\n        """\n        Generate CoM trajectory from desired ZMP trajectory\n        """\n        timesteps = int(duration / dt)\n        com_trajectory = np.zeros((timesteps, 3))\n        com_velocity = np.zeros((timesteps, 3))\n        com_acceleration = np.zeros((timesteps, 3))\n\n        # Initial conditions\n        com_pos = initial_com.copy()\n        com_vel = np.zeros(3)\n\n        for i in range(timesteps):\n            t = i * dt\n\n            # Get desired ZMP at current time\n            zmp_desired = self.interpolate_zmp_trajectory(zmp_trajectory, t)\n\n            # Calculate CoM acceleration from ZMP\n            # Using inverted pendulum model: (\u1e8d, \xff) = g/h * (com - zmp)\n            com_acc[0] = (self.g / self.h) * (com_pos[0] - zmp_desired[0])\n            com_acc[1] = (self.g / self.h) * (com_pos[1] - zmp_desired[1])\n            com_acc[2] = 0  # Assume constant height\n\n            # Integrate to get velocity and position\n            com_vel += com_acc * dt\n            com_pos += com_vel * dt\n\n            com_trajectory[i] = com_pos.copy()\n            com_velocity[i] = com_vel.copy()\n            com_acceleration[i] = com_acc.copy()\n\n        return com_trajectory, com_velocity, com_acceleration\n\n    def interpolate_zmp_trajectory(self, zmp_trajectory, time):\n        """\n        Interpolate ZMP trajectory at given time\n        """\n        # Simplified linear interpolation\n        return zmp_trajectory[0]  # Placeholder\n'})}),"\n",(0,i.jsx)(e.h3,{id:"preview-control",children:"Preview Control"}),"\n",(0,i.jsx)(e.p,{children:"Preview control uses future ZMP reference to improve tracking:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class PreviewController:\n    def __init__(self, robot_height, preview_horizon=2.0, dt=0.01):\n        self.h = robot_height\n        self.preview_horizon = preview_horizon\n        self.dt = dt\n        self.N = int(preview_horizon / dt)\n\n        # Calculate preview control gain\n        self.K_preview = self.calculate_preview_gain()\n\n    def calculate_preview_gain(self):\n        """\n        Calculate preview control gain matrix\n        """\n        # This involves solving Riccati equations and calculating gains\n        # Simplified implementation\n        A_c = np.array([[0, 1], [self.g/self.h, 0]])  # Continuous system matrix\n        B_c = np.array([[0], [-self.g/self.h]])      # Continuous input matrix\n\n        # Discretize the system\n        A_d = np.eye(2) + A_c * self.dt\n        B_d = B_c * self.dt\n\n        # For simplicity, return a basic gain matrix\n        # Full implementation would solve the discrete-time Riccati equation\n        return np.array([1.0, 0.1])\n\n    def compute_control(self, current_state, future_zmp_reference):\n        """\n        Compute control using preview of future ZMP reference\n        """\n        # current_state = [com_x, com_x_dot]\n        # future_zmp_reference = array of future ZMP values\n\n        # Implement preview control law\n        control = 0\n\n        # Feedback term\n        feedback_gain = np.array([10, 2])  # [position, velocity gains]\n        tracking_error = current_state  # Simplified\n        control += feedback_gain @ tracking_error\n\n        # Preview term (sum of future reference weighted by preview gains)\n        for k in range(min(self.N, len(future_zmp_reference))):\n            preview_gain = self.calculate_preview_gain_for_step(k)\n            control += preview_gain * future_zmp_reference[k]\n\n        return control\n\n    def calculate_preview_gain_for_step(self, k):\n        """\n        Calculate preview gain for k steps ahead\n        """\n        # This would come from the solution of the Riccati equation\n        # Simplified implementation\n        return 0.01 * np.exp(-k * 0.1)  # Decaying gain\n'})}),"\n",(0,i.jsx)(e.h2,{id:"balance-control",children:"Balance Control"}),"\n",(0,i.jsx)(e.h3,{id:"linear-inverted-pendulum-model-lipm",children:"Linear Inverted Pendulum Model (LIPM)"}),"\n",(0,i.jsx)(e.p,{children:"The LIPM is commonly used for humanoid balance control:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class LIPMController:\n    def __init__(self, com_height, gravity=9.81):\n        self.h = com_height\n        self.g = gravity\n        self.omega = np.sqrt(self.g / self.h)\n\n    def calculate_capture_point(self, com_pos, com_vel):\n        """\n        Calculate capture point for balance recovery\n        """\n        # Capture point: where to step to stop the CoM\n        capture_point = com_pos + com_vel / self.omega\n        return capture_point\n\n    def generate_balance_trajectory(self, current_com, current_com_vel, target_com, duration, dt=0.01):\n        """\n        Generate CoM trajectory for balance control\n        """\n        timesteps = int(duration / dt)\n        trajectory = np.zeros((timesteps, 3))\n\n        for i in range(timesteps):\n            t = i * dt\n            progress = t / duration\n\n            # Exponential decay toward target\n            remaining_time = duration - t\n            decay_factor = np.exp(-self.omega * remaining_time)\n\n            # Calculate current CoM position\n            current_pos = (1 - decay_factor) * target_com + decay_factor * current_com + \\\n                         decay_factor / self.omega * current_com_vel\n\n            trajectory[i] = current_pos\n\n        return trajectory\n'})}),"\n",(0,i.jsx)(e.h3,{id:"whole-body-control",children:"Whole-Body Control"}),"\n",(0,i.jsx)(e.p,{children:"For complex humanoid robots, whole-body control considers all tasks simultaneously:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class WholeBodyController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.n_joints = robot_model.n_joints\n        self.n_contacts = 4  # Assuming 2 feet contacts (3 DOF each = 6, simplified to 4)\n\n    def compute_whole_body_control(self, tasks, contact_points, external_forces=None):\n        """\n        Compute whole-body control considering multiple tasks and contacts\n        """\n        # tasks: list of (task_type, task_value, priority, weight)\n        # contact_points: points where robot contacts environment\n\n        # Formulate as optimization problem:\n        # min ||Ax - b||^2 + reg_term\n        # subject to: Cx = d (equality constraints)\n\n        # Build task hierarchy\n        A_tasks, b_tasks = self.build_task_jacobians(tasks)\n        A_contacts, b_contacts = self.build_contact_constraints(contact_points)\n\n        # Combine all constraints\n        A_total = np.vstack([A_tasks, A_contacts])\n        b_total = np.hstack([b_tasks, b_contacts])\n\n        # Solve using weighted least squares\n        weights = self.calculate_task_weights(tasks)\n        W = np.diag(weights)\n\n        # Regularized solution\n        reg_param = 0.001\n        I_reg = reg_param * np.eye(A_total.shape[1])\n\n        # Solve: (A^T * W * A + I_reg) * x = A^T * W * b\n        AtWA = A_total.T @ W @ A_total + I_reg\n        AtWb = A_total.T @ W @ b_total\n\n        solution = np.linalg.solve(AtWA, AtWb)\n\n        return solution\n\n    def build_task_jacobians(self, tasks):\n        """\n        Build Jacobian matrix for all tasks\n        """\n        total_rows = sum(len(task[1]) for task in tasks)  # Size of all task errors\n        A = np.zeros((total_rows, self.n_joints + 6 * self.n_contacts))  # +6 for contact forces\n        b = np.zeros(total_rows)\n\n        row_idx = 0\n        for task_type, task_value, priority, weight in tasks:\n            if task_type == "end_effector_pose":\n                jacobian = self.get_end_effector_jacobian(task_value[\'link_name\'])\n                task_error = self.calculate_pose_error(task_value[\'desired\'], task_value[\'current\'])\n\n            elif task_type == "com_position":\n                jacobian = self.get_com_jacobian()\n                task_error = task_value[\'desired\'] - task_value[\'current\']\n\n            elif task_type == "posture":\n                jacobian = self.get_posture_jacobian()\n                task_error = task_value[\'desired\'] - task_value[\'current\']\n\n            # Add to matrices\n            A[row_idx:row_idx+len(task_error), :self.n_joints] = jacobian\n            b[row_idx:row_idx+len(task_error)] = task_error\n            row_idx += len(task_error)\n\n        return A, b\n\n    def build_contact_constraints(self, contact_points):\n        """\n        Build equality constraints for contact points\n        """\n        # No sliding, no penetration constraints\n        n_constraints = len(contact_points) * 3  # 3 DOF per contact point\n        A = np.zeros((n_constraints, self.n_joints + 6 * len(contact_points)))\n        b = np.zeros(n_constraints)\n\n        for i, contact in enumerate(contact_points):\n            # Contact point should have zero velocity (no sliding)\n            # and appropriate force constraints\n            start_row = i * 3\n            contact_jacobian = self.get_contact_jacobian(contact[\'link_name\'], contact[\'point\'])\n\n            # Velocity constraint: J * qdot = 0\n            A[start_row:start_row+3, :self.n_joints] = contact_jacobian\n\n        return A, b\n\n    def calculate_task_weights(self, tasks):\n        """\n        Calculate weights based on task priorities\n        """\n        total_size = sum(len(task[1]) for task in tasks)\n        weights = np.ones(total_size)\n        current_idx = 0\n\n        for task_type, task_value, priority, weight in tasks:\n            task_size = len(task_value) if isinstance(task_value, (list, np.ndarray)) else 3\n            weights[current_idx:current_idx+task_size] = weight\n            current_idx += task_size\n\n        return weights\n'})}),"\n",(0,i.jsx)(e.h2,{id:"control-implementation-example",children:"Control Implementation Example"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class HumanoidBalanceController:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.zmp_controller = ZMPController(robot_height=0.8)\n        self.lipm_controller = LIPMController(com_height=0.8)\n        self.whole_body_controller = WholeBodyController(robot_model)\n\n        # State estimators\n        self.state_estimator = self.initialize_state_estimator()\n\n    def control_step(self, sensor_data, dt):\n        \"\"\"\n        Main control step for humanoid balance\n        \"\"\"\n        # 1. State estimation\n        current_state = self.estimate_state(sensor_data)\n\n        # 2. Balance planning\n        desired_zmp = self.plan_balance(current_state)\n\n        # 3. Trajectory generation\n        com_trajectory = self.generate_com_trajectory(desired_zmp, current_state['com'])\n\n        # 4. Whole-body control\n        control_commands = self.compute_control_commands(\n            current_state, com_trajectory, sensor_data\n        )\n\n        # 5. Apply control\n        self.send_control_commands(control_commands)\n\n        return control_commands\n\n    def estimate_state(self, sensor_data):\n        \"\"\"\n        Estimate robot state from sensor data\n        \"\"\"\n        # Combine IMU, joint encoders, force/torque sensors\n        com_pos = self.estimate_com_position(sensor_data)\n        com_vel = self.estimate_com_velocity(sensor_data)\n        com_acc = self.estimate_com_acceleration(sensor_data)\n\n        joint_positions = sensor_data['joint_positions']\n        joint_velocities = sensor_data['joint_velocities']\n\n        # Foot contact states\n        left_foot_contact = sensor_data['left_foot_force'] > 10  # Threshold\n        right_foot_contact = sensor_data['right_foot_force'] > 10\n\n        return {\n            'com': com_pos,\n            'com_vel': com_vel,\n            'com_acc': com_acc,\n            'joint_positions': joint_positions,\n            'joint_velocities': joint_velocities,\n            'left_foot_contact': left_foot_contact,\n            'right_foot_contact': right_foot_contact\n        }\n\n    def plan_balance(self, current_state):\n        \"\"\"\n        Plan balance strategy based on current state\n        \"\"\"\n        # Calculate current ZMP\n        current_zmp = self.zmp_controller.calculate_zmp_from_com(\n            current_state['com'],\n            current_state['com_vel'],\n            current_state['com_acc']\n        )\n\n        # Calculate capture point\n        capture_point = self.lipm_controller.calculate_capture_point(\n            current_state['com'][:2],\n            current_state['com_vel'][:2]\n        )\n\n        # Determine balance strategy\n        support_polygon = self.calculate_support_polygon(current_state)\n\n        if not self.is_zmp_in_support(current_zmp, support_polygon):\n            # Generate recovery ZMP trajectory\n            recovery_zmp = self.generate_recovery_trajectory(current_zmp, capture_point)\n            return recovery_zmp\n        else:\n            # Maintain current balance\n            return current_zmp\n\n    def generate_recovery_trajectory(self, current_zmp, capture_point):\n        \"\"\"\n        Generate ZMP trajectory for balance recovery\n        \"\"\"\n        # Move ZMP toward capture point to initiate recovery step\n        step_duration = 0.8  # 800ms step\n        dt = 0.01\n        timesteps = int(step_duration / dt)\n\n        recovery_trajectory = np.zeros((timesteps, 3))\n\n        for i in range(timesteps):\n            t = i * dt\n            # Smooth transition from current ZMP to capture point\n            alpha = 0.5 * (1 - np.cos(np.pi * t / step_duration))  # S-curve\n            recovery_trajectory[i] = (1 - alpha) * current_zmp + alpha * np.append(capture_point, [0])\n\n        return recovery_trajectory\n\n    def compute_control_commands(self, current_state, com_trajectory, sensor_data):\n        \"\"\"\n        Compute final control commands\n        \"\"\"\n        # Define tasks with priorities\n        tasks = [\n            # High priority: maintain CoM trajectory\n            ('com_position', {\n                'desired': com_trajectory[0],  # Next desired CoM position\n                'current': current_state['com']\n            }, 1, 100.0),\n\n            # Medium priority: maintain foot positions\n            ('left_foot_position', {\n                'desired': self.get_left_foot_target(),\n                'current': self.get_current_left_foot_position()\n            }, 2, 50.0),\n\n            # Low priority: joint posture\n            ('posture', {\n                'desired': self.get_nominal_joint_positions(),\n                'current': current_state['joint_positions']\n            }, 3, 1.0)\n        ]\n\n        # Define contact constraints\n        contact_points = [\n            {'link_name': 'left_foot', 'point': [0, 0, 0]},\n            {'link_name': 'right_foot', 'point': [0, 0, 0]}\n        ]\n\n        # Compute whole-body control\n        control_solution = self.whole_body_controller.compute_whole_body_control(\n            tasks, contact_points\n        )\n\n        # Extract joint torques (first n_joints elements)\n        joint_torques = control_solution[:self.model.n_joints]\n\n        # Extract contact forces (remaining elements)\n        contact_forces = control_solution[self.model.n_joints:]\n\n        return {\n            'joint_torques': joint_torques,\n            'contact_forces': contact_forces\n        }\n\n    def send_control_commands(self, control_commands):\n        \"\"\"\n        Send control commands to robot hardware\n        \"\"\"\n        # Interface with robot's low-level controllers\n        # This would typically use ROS messages, EtherCAT, or other communication protocols\n        joint_torques = control_commands['joint_torques']\n\n        # Apply joint limits and safety checks\n        limited_torques = self.apply_joint_limits(joint_torques)\n\n        # Send to hardware\n        self.robot_interface.send_joint_commands(limited_torques)\n\n    def apply_joint_limits(self, torques):\n        \"\"\"\n        Apply safety limits to control commands\n        \"\"\"\n        max_torque = 100.0  # Example limit (Nm)\n        return np.clip(torques, -max_torque, max_torque)\n"})}),"\n",(0,i.jsx)(e.h2,{id:"advanced-control-techniques",children:"Advanced Control Techniques"}),"\n",(0,i.jsx)(e.h3,{id:"model-predictive-control-mpc",children:"Model Predictive Control (MPC)"}),"\n",(0,i.jsx)(e.p,{children:"MPC is particularly useful for humanoid robots due to its ability to handle constraints:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class ModelPredictiveController:\n    def __init__(self, prediction_horizon=10, dt=0.01):\n        self.N = prediction_horizon\n        self.dt = dt\n        self.Q = np.eye(6) * 10  # State cost matrix\n        self.R = np.eye(3) * 0.1  # Control cost matrix\n        self.P = np.eye(6) * 50  # Terminal cost matrix\n\n    def solve_mpc(self, current_state, reference_trajectory):\n        """\n        Solve MPC optimization problem\n        """\n        # This would typically use a QP solver like OSQP or CVXOPT\n        # For this example, we\'ll outline the structure\n\n        # Predict system evolution over horizon\n        predicted_states = []\n        control_sequence = []\n\n        state = current_state.copy()\n\n        for k in range(self.N):\n            # Calculate optimal control for this step\n            ref_k = reference_trajectory[k] if k < len(reference_trajectory) else reference_trajectory[-1]\n\n            # Simple LQR solution (in practice, this would be a constrained QP)\n            control = self.calculate_lqr_control(state, ref_k)\n\n            # Apply control and predict next state\n            state = self.predict_next_state(state, control)\n            predicted_states.append(state.copy())\n            control_sequence.append(control.copy())\n\n        return control_sequence[0]  # Return first control in sequence\n\n    def calculate_lqr_control(self, state, reference):\n        """\n        Calculate LQR control law\n        """\n        # Solve Riccati equation offline, then apply feedback law\n        # u = -K * (x - x_ref)\n        error = state - reference\n        K = self.calculate_lqr_gain()  # Pre-computed offline\n        control = -K @ error\n        return control\n\n    def calculate_lqr_gain(self):\n        """\n        Calculate LQR gain matrix (typically done offline)\n        """\n        # Solve: A^T * P * A - P - A^T * P * B * (R + B^T * P * B)^(-1) * B^T * P * A + Q = 0\n        # Return: K = (R + B^T * P * B)^(-1) * B^T * P * A\n        return np.array([[1, 2, 1, 0.5, 0.1, 0.1]])  # Placeholder\n'})}),"\n",(0,i.jsx)(e.h2,{id:"control-architecture",children:"Control Architecture"}),"\n",(0,i.jsx)(e.h3,{id:"hierarchical-control-structure",children:"Hierarchical Control Structure"}),"\n",(0,i.jsx)(e.p,{children:"Humanoid robots typically use a hierarchical control structure:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           High-Level Planner            \u2502\n\u2502  (Walking pattern, trajectory planning) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Pattern Generator               \u2502\n\u2502     (ZMP, CoM, foot placement)         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Feedback Controller             \u2502\n\u2502     (Balance, impedance control)        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Joint Servo Level               \u2502\n\u2502      (PID, current control)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(e.h2,{id:"simulation-and-testing",children:"Simulation and Testing"}),"\n",(0,i.jsx)(e.h3,{id:"simulation-environment",children:"Simulation Environment"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class HumanoidControlSimulator:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.controller = HumanoidBalanceController(robot_model)\n        self.dt = 0.01\n\n    def simulate_control_step(self, current_state):\n        \"\"\"\n        Simulate one control step\n        \"\"\"\n        # Get sensor data from simulation\n        sensor_data = self.get_sensor_data(current_state)\n\n        # Apply control\n        commands = self.controller.control_step(sensor_data, self.dt)\n\n        # Update simulation with commands\n        next_state = self.update_dynamics(current_state, commands['joint_torques'])\n\n        return next_state, commands\n\n    def get_sensor_data(self, state):\n        \"\"\"\n        Simulate sensor readings\n        \"\"\"\n        # Add realistic sensor noise\n        joint_pos = state['joint_positions'] + np.random.normal(0, 0.001, size=state['joint_positions'].shape)\n        joint_vel = state['joint_velocities'] + np.random.normal(0, 0.01, size=state['joint_velocities'].shape)\n\n        # IMU simulation\n        imu_data = self.simulate_imu(state)\n\n        return {\n            'joint_positions': joint_pos,\n            'joint_velocities': joint_vel,\n            'imu_data': imu_data,\n            'force_torque_data': self.simulate_force_sensors(state)\n        }\n\n    def update_dynamics(self, current_state, joint_torques):\n        \"\"\"\n        Update robot dynamics with control torques\n        \"\"\"\n        # Apply joint torques and simulate forward dynamics\n        # This would use numerical integration of the equations of motion\n        # using methods like Runge-Kutta or Euler integration\n\n        # Simplified example using Euler integration\n        M = self.model.mass_matrix(current_state['joint_positions'])\n        C = self.model.coriolis_matrix(current_state['joint_positions'], current_state['joint_velocities'])\n        g = self.model.gravity_vector(current_state['joint_positions'])\n\n        # M*qdd + C*qd + g = tau\n        joint_acc = np.linalg.solve(M, joint_torques - C @ current_state['joint_velocities'] - g)\n\n        # Integrate to get new state\n        new_joint_velocities = current_state['joint_velocities'] + joint_acc * self.dt\n        new_joint_positions = current_state['joint_positions'] + new_joint_velocities * self.dt\n\n        return {\n            'joint_positions': new_joint_positions,\n            'joint_velocities': new_joint_velocities\n        }\n"})}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"Dynamics and control form the core of humanoid robot functionality. The complex multi-body dynamics of humanoid robots require sophisticated control approaches that can handle:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-constraint optimization"}),": Balancing multiple objectives simultaneously"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Real-time computation"}),": Meeting strict timing requirements for stability"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Disturbance rejection"}),": Handling external forces and environmental interactions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety considerations"}),": Ensuring stable and safe operation"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Key techniques covered in this section include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Inverse dynamics control"}),": Linearizing robot dynamics for precise control"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Operational space control"}),": Controlling tasks in end-effector space"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Impedance control"}),": Achieving compliant behavior for safe interaction"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"ZMP-based walking"}),": Ensuring stable bipedal locomotion"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Whole-body control"}),": Coordinating all robot degrees of freedom"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Balance recovery"}),": Maintaining stability under disturbances"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The next section will focus specifically on bipedal locomotion, which builds upon these dynamic control foundations to enable humanoid robots to walk effectively."})]})}function _(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>s});var o=t(6540);const i={},r=o.createContext(i);function a(n){const e=o.useContext(r);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);