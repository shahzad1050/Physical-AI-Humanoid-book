"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[5662],{8453:(n,e,i)=>{i.d(e,{R:()=>a,x:()=>r});var t=i(6540);const o={},s=t.createContext(o);function a(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),t.createElement(s.Provider,{value:e},n.children)}},9256:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module2/unity-visualization","title":"Unity for Robot Visualization","description":"Introduction to Unity for Robotics","source":"@site/docs/module2/unity-visualization.md","sourceDirName":"module2","slug":"/module2/unity-visualization","permalink":"/Physical-AI-Humanoid-book/docs/module2/unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/user/physical-ai-humanoid-robotics/tree/main/docs/module2/unity-visualization.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Physics and Sensor Simulation","permalink":"/Physical-AI-Humanoid-book/docs/module2/physics-sensor-simulation"},"next":{"title":"URDF and SDF Formats","permalink":"/Physical-AI-Humanoid-book/docs/module2/urdf-sdf-formats"}}');var o=i(4848),s=i(8453);const a={},r="Unity for Robot Visualization",l={},c=[{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Why Unity for Robotics?",id:"why-unity-for-robotics",level:2},{value:"Advantages",id:"advantages",level:3},{value:"Use Cases in Robotics",id:"use-cases-in-robotics",level:3},{value:"Unity Robotics Setup",id:"unity-robotics-setup",level:2},{value:"Installation Requirements",id:"installation-requirements",level:3},{value:"Installing Unity Robotics Tools",id:"installing-unity-robotics-tools",level:3},{value:"Unity ROS Integration",id:"unity-ros-integration",level:2},{value:"ROS-TCP-Connector",id:"ros-tcp-connector",level:3},{value:"Setting Up the Connection",id:"setting-up-the-connection",level:3},{value:"Creating Robot Models in Unity",id:"creating-robot-models-in-unity",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Robot Structure in Unity",id:"robot-structure-in-unity",level:3},{value:"Joint Control System",id:"joint-control-system",level:3},{value:"Sensor Simulation in Unity",id:"sensor-simulation-in-unity",level:2},{value:"Camera Sensors",id:"camera-sensors",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:3},{value:"Unity Perception Package",id:"unity-perception-package",level:2},{value:"Semantic Segmentation",id:"semantic-segmentation",level:3},{value:"Dataset Generation",id:"dataset-generation",level:3},{value:"Digital Twin Implementation",id:"digital-twin-implementation",level:2},{value:"Real-time Synchronization",id:"real-time-synchronization",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Level of Detail (LOD)",id:"level-of-detail-lod",level:3},{value:"Occlusion Culling",id:"occlusion-culling",level:3},{value:"VR Integration for Teleoperation",id:"vr-integration-for-teleoperation",level:2},{value:"VR Teleoperation Interface",id:"vr-teleoperation-interface",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Scene Organization",id:"1-scene-organization",level:3},{value:"2. Resource Management",id:"2-resource-management",level:3},{value:"3. Network Communication",id:"3-network-communication",level:3},{value:"4. Physics Settings",id:"4-physics-settings",level:3},{value:"Integration Workflow",id:"integration-workflow",level:2},{value:"Development Pipeline",id:"development-pipeline",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Connection Problems",id:"connection-problems",level:3},{value:"Performance Issues",id:"performance-issues",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"unity-for-robot-visualization",children:"Unity for Robot Visualization"})}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Unity is a powerful 3D development platform that has gained significant traction in robotics for creating high-fidelity visualizations, simulations, and digital twins. While traditionally used for gaming, Unity's real-time rendering capabilities, physics engine, and extensibility make it an excellent choice for robotics applications."}),"\n",(0,o.jsx)(e.h2,{id:"why-unity-for-robotics",children:"Why Unity for Robotics?"}),"\n",(0,o.jsx)(e.h3,{id:"advantages",children:"Advantages"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-Quality Rendering"}),": State-of-the-art graphics for photorealistic simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time Performance"}),": Optimized for interactive applications"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extensive Asset Library"}),": Thousands of 3D models, materials, and environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cross-Platform Support"}),": Deploy to multiple platforms and devices"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Active Community"}),": Large developer community with extensive resources"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Flexible Integration"}),": APIs for connecting with external systems"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"use-cases-in-robotics",children:"Use Cases in Robotics"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-fidelity simulation"})," for perception system training"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Digital twin visualization"})," for monitoring real robots"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Virtual reality (VR) interfaces"})," for robot teleoperation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Training environments"})," for reinforcement learning"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Public demonstrations"})," and educational tools"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"unity-robotics-setup",children:"Unity Robotics Setup"}),"\n",(0,o.jsx)(e.h3,{id:"installation-requirements",children:"Installation Requirements"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Hub"}),": Download from Unity's official website"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Editor"}),": Install version 2021.3 LTS or later"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Robotics Hub"}),": Extension for robotics-specific tools"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"installing-unity-robotics-tools",children:"Installing Unity Robotics Tools"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Through Unity Package Manager:\n# Window \u2192 Package Manager \u2192 Unity Registry\n# Install:\n# - Unity Robotics Hub\n# - ROS-TCP-Connector\n# - Unity Perception\n# - ML-Agents (for AI training)\n"})}),"\n",(0,o.jsx)(e.h2,{id:"unity-ros-integration",children:"Unity ROS Integration"}),"\n",(0,o.jsx)(e.h3,{id:"ros-tcp-connector",children:"ROS-TCP-Connector"}),"\n",(0,o.jsx)(e.p,{children:"The ROS-TCP-Connector package enables communication between Unity and ROS 2:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Std;\n\npublic class RobotController : MonoBehaviour\n{\n    ROSConnection ros;\n\n    void Start()\n    {\n        // Connect to ROS\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<UInt64Msg>("robot_command");\n    }\n\n    void Update()\n    {\n        // Send a message to ROS\n        if (Input.GetKeyDown(KeyCode.Space))\n        {\n            ros.Publish("robot_command", new UInt64Msg(1));\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"setting-up-the-connection",children:"Setting Up the Connection"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Start ROS 2 bridge"})," in your terminal:"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Terminal 1\nsource /opt/ros/humble/setup.bash\nsource install/setup.bash\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=127.0.0.1 -p ROS_TCP_PORT:=10000\n"})}),"\n",(0,o.jsxs)(e.ol,{start:"2",children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Configure Unity"})," to connect to the bridge:"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// In Unity, configure the ROS connection\nusing Unity.Robotics.ROSTCPConnector;\n\npublic class ROSConnectionSetup : MonoBehaviour\n{\n    public string rosIPAddress = "127.0.0.1";\n    public int rosPort = 10000;\n\n    void Start()\n    {\n        ROSConnection.instance = ROSConnection.GetOrCreateInstance();\n        ROSConnection.instance.RosIPAddress = rosIPAddress;\n        ROSConnection.instance.RosPort = rosPort;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"creating-robot-models-in-unity",children:"Creating Robot Models in Unity"}),"\n",(0,o.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,o.jsx)(e.p,{children:"Unity supports several 3D model formats:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"FBX"}),": Recommended for complex models with animations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"OBJ"}),": Simple geometry import"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"DAE"}),": Collada format for interchange"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"USD"}),": Universal Scene Description (Unity native)"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"robot-structure-in-unity",children:"Robot Structure in Unity"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class RobotModel : MonoBehaviour\n{\n    [Header("Robot Joints")]\n    public Transform baseLink;\n    public Transform joint1;\n    public Transform joint2;\n    public Transform endEffector;\n\n    [Header("Joint Limits")]\n    public float joint1Min = -90f;\n    public float joint1Max = 90f;\n    public float joint2Min = -45f;\n    public float joint2Max = 45f;\n\n    // Forward kinematics calculation\n    public Vector3 CalculateEndEffectorPosition()\n    {\n        return endEffector.position;\n    }\n\n    // Inverse kinematics (simplified)\n    public void SetJointAngles(float angle1, float angle2)\n    {\n        angle1 = Mathf.Clamp(angle1, joint1Min, joint1Max);\n        angle2 = Mathf.Clamp(angle2, joint2Min, joint2Max);\n\n        joint1.localEulerAngles = new Vector3(0, 0, angle1);\n        joint2.localEulerAngles = new Vector3(0, 0, angle2);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"joint-control-system",children:"Joint Control System"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class JointController : MonoBehaviour\n{\n    ROSConnection ros;\n    public string jointStateTopic = "/joint_states";\n    public Transform[] joints;\n    public string[] jointNames;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Subscribe<JointStateMsg>(jointStateTopic, OnJointStateReceived);\n    }\n\n    void OnJointStateReceived(JointStateMsg jointState)\n    {\n        for (int i = 0; i < jointNames.Length; i++)\n        {\n            int jointIndex = System.Array.IndexOf(jointState.name, jointNames[i]);\n            if (jointIndex >= 0 && jointIndex < jointState.position.Length)\n            {\n                // Apply joint position to Unity transform\n                joints[i].localEulerAngles = new Vector3(0, 0, (float)jointState.position[jointIndex] * Mathf.Rad2Deg);\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"sensor-simulation-in-unity",children:"Sensor Simulation in Unity"}),"\n",(0,o.jsx)(e.h3,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,o.jsx)(e.p,{children:"Unity's built-in cameras can simulate various types of vision sensors:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class UnityCameraSensor : MonoBehaviour\n{\n    Camera cam;\n    ROSConnection ros;\n    public string imageTopic = "/camera/image_raw";\n    public int imageWidth = 640;\n    public int imageHeight = 480;\n    public float updateRate = 30.0f;\n\n    RenderTexture renderTexture;\n    Texture2D texture2D;\n\n    void Start()\n    {\n        cam = GetComponent<Camera>();\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Create render texture for camera\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\n        texture2D = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);\n        cam.targetTexture = renderTexture;\n\n        InvokeRepeating("CaptureAndSendImage", 0, 1.0f / updateRate);\n    }\n\n    void CaptureAndSendImage()\n    {\n        // Set the active render texture\n        RenderTexture.active = renderTexture;\n\n        // Read pixels from the render texture\n        texture2D.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\n        texture2D.Apply();\n\n        // Convert to ROS message format (simplified)\n        byte[] imageData = texture2D.EncodeToJPG();\n\n        // Send image via ROS (implementation depends on message format)\n        // ros.Publish(imageTopic, imageMsg);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Unity can simulate LIDAR sensors using raycasting:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing System.Collections.Generic;\n\npublic class UnityLidar : MonoBehaviour\n{\n    public int horizontalSamples = 720;\n    public int verticalSamples = 1;\n    public float minAngle = -Mathf.PI;\n    public float maxAngle = Mathf.PI;\n    public float maxRange = 30.0f;\n    public LayerMask detectionMask = -1; // All layers\n\n    ROSConnection ros;\n    public string scanTopic = "/scan";\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        InvokeRepeating("SimulateLidar", 0, 0.1f); // 10Hz\n    }\n\n    void SimulateLidar()\n    {\n        List<float> ranges = new List<float>();\n\n        float angleIncrement = (maxAngle - minAngle) / horizontalSamples;\n\n        for (int i = 0; i < horizontalSamples; i++)\n        {\n            float angle = minAngle + i * angleIncrement;\n\n            Vector3 direction = new Vector3(\n                Mathf.Cos(angle),\n                0,\n                Mathf.Sin(angle)\n            );\n\n            RaycastHit hit;\n            if (Physics.Raycast(transform.position, transform.TransformDirection(direction),\n                              out hit, maxRange, detectionMask))\n            {\n                ranges.Add(hit.distance);\n            }\n            else\n            {\n                ranges.Add(maxRange); // No obstacle detected\n            }\n        }\n\n        // Publish ranges to ROS (simplified)\n        // ros.Publish(scanTopic, laserScanMsg);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"unity-perception-package",children:"Unity Perception Package"}),"\n",(0,o.jsx)(e.p,{children:"The Unity Perception package provides tools for generating synthetic training data:"}),"\n",(0,o.jsx)(e.h3,{id:"semantic-segmentation",children:"Semantic Segmentation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Perception.GroundTruth;\nusing Unity.Perception.GroundTruth.LabelManagement;\n\npublic class SemanticSegmentationSetup : MonoBehaviour\n{\n    void Start()\n    {\n        // Assign semantic labels to objects\n        AssignSemanticLabels();\n    }\n\n    void AssignSemanticLabels()\n    {\n        GameObject[] objects = GameObject.FindGameObjectsWithTag("SemanticObject");\n\n        foreach (GameObject obj in objects)\n        {\n            var labeler = obj.GetComponent<SemanticLabeler>();\n            if (labeler == null)\n                labeler = obj.AddComponent<SemanticLabeler>();\n\n            // Assign labels based on object type\n            if (obj.tag == "Robot")\n                labeler.labelId = 1;\n            else if (obj.tag == "Obstacle")\n                labeler.labelId = 2;\n            else if (obj.tag == "Ground")\n                labeler.labelId = 3;\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"dataset-generation",children:"Dataset Generation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Perception.GroundTruth;\nusing System.Collections;\n\npublic class DatasetGenerator : MonoBehaviour\n{\n    public int datasetSize = 1000;\n    public float captureInterval = 0.5f;\n\n    void Start()\n    {\n        StartCoroutine(GenerateDataset());\n    }\n\n    IEnumerator GenerateDataset()\n    {\n        for (int i = 0; i < datasetSize; i++)\n        {\n            // Move objects to random positions\n            RandomizeScene();\n\n            // Capture ground truth data\n            CaptureGroundTruth();\n\n            yield return new WaitForSeconds(captureInterval);\n        }\n    }\n\n    void RandomizeScene()\n    {\n        // Randomly position objects in the scene\n        GameObject[] sceneObjects = GameObject.FindGameObjectsWithTag("RandomObject");\n\n        foreach (GameObject obj in sceneObjects)\n        {\n            Vector3 randomPos = new Vector3(\n                Random.Range(-5f, 5f),\n                Random.Range(0f, 2f),\n                Random.Range(-5f, 5f)\n            );\n\n            obj.transform.position = randomPos;\n\n            // Random rotation\n            obj.transform.rotation = Random.rotation;\n        }\n    }\n\n    void CaptureGroundTruth()\n    {\n        // Trigger capture of all ground truth data\n        // This would typically save images and annotations\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"digital-twin-implementation",children:"Digital Twin Implementation"}),"\n",(0,o.jsx)(e.h3,{id:"real-time-synchronization",children:"Real-time Synchronization"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Nav;\nusing RosMessageTypes.Geometry;\n\npublic class DigitalTwin : MonoBehaviour\n{\n    ROSConnection ros;\n    public string tfTopic = "/tf";\n    public string odomTopic = "/odom";\n\n    // Store robot state\n    Vector3 realPosition;\n    Quaternion realRotation;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Subscribe<OdometryMsg>(odomTopic, OnOdometryReceived);\n        ros.Subscribe<TFMessage>(tfTopic, OnTFReceived);\n    }\n\n    void OnOdometryReceived(OdometryMsg odom)\n    {\n        // Update digital twin with real robot pose\n        realPosition = new Vector3(\n            (float)odom.pose.pose.position.x,\n            (float)odom.pose.pose.position.y,\n            (float)odom.pose.pose.position.z\n        );\n\n        realRotation = new Quaternion(\n            (float)odom.pose.pose.orientation.x,\n            (float)odom.pose.pose.orientation.y,\n            (float)odom.pose.pose.orientation.z,\n            (float)odom.pose.pose.orientation.w\n        );\n\n        // Apply to Unity object\n        transform.position = realPosition;\n        transform.rotation = realRotation;\n    }\n\n    void OnTFReceived(TFMessage tf)\n    {\n        // Handle transform updates for multi-link robots\n        foreach (var transform in tf.transforms)\n        {\n            // Update corresponding Unity object\n            UpdateLinkPose(transform.child_frame_id, transform.transform);\n        }\n    }\n\n    void UpdateLinkPose(string frameId, TransformMsg tf)\n    {\n        GameObject linkObject = GameObject.Find(frameId);\n        if (linkObject != null)\n        {\n            linkObject.transform.position = new Vector3(\n                (float)tf.translation.x,\n                (float)tf.translation.y,\n                (float)tf.translation.z\n            );\n\n            linkObject.transform.rotation = new Quaternion(\n                (float)tf.rotation.x,\n                (float)tf.rotation.y,\n                (float)tf.rotation.z,\n                (float)tf.rotation.w\n            );\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsx)(e.h3,{id:"level-of-detail-lod",children:"Level of Detail (LOD)"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:"using UnityEngine;\n\npublic class RobotLOD : MonoBehaviour\n{\n    public float[] lodDistances = {10f, 30f, 50f};\n    public GameObject[] lodObjects;\n\n    Camera mainCamera;\n\n    void Start()\n    {\n        mainCamera = Camera.main;\n        UpdateLOD();\n    }\n\n    void Update()\n    {\n        UpdateLOD();\n    }\n\n    void UpdateLOD()\n    {\n        if (mainCamera == null) return;\n\n        float distance = Vector3.Distance(transform.position, mainCamera.transform.position);\n\n        for (int i = 0; i < lodDistances.Length; i++)\n        {\n            if (distance <= lodDistances[i])\n            {\n                ActivateLOD(i);\n                return;\n            }\n        }\n\n        // Use lowest detail if beyond all distances\n        ActivateLOD(lodObjects.Length - 1);\n    }\n\n    void ActivateLOD(int lodIndex)\n    {\n        for (int i = 0; i < lodObjects.Length; i++)\n        {\n            if (lodObjects[i] != null)\n            {\n                lodObjects[i].SetActive(i == lodIndex);\n            }\n        }\n    }\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"occlusion-culling",children:"Occlusion Culling"}),"\n",(0,o.jsx)(e.p,{children:"Enable Unity's built-in occlusion culling for better performance:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// In Unity Editor: Window \u2192 Rendering \u2192 Occlusion Culling\n// Mark static objects as "Occluder Static" or "Occludee Static"\n'})}),"\n",(0,o.jsx)(e.h2,{id:"vr-integration-for-teleoperation",children:"VR Integration for Teleoperation"}),"\n",(0,o.jsx)(e.h3,{id:"vr-teleoperation-interface",children:"VR Teleoperation Interface"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.XR;\nusing Unity.Robotics.ROSTCPConnector;\n\npublic class VRTeleoperation : MonoBehaviour\n{\n    ROSConnection ros;\n    public string commandTopic = "/teleop_command";\n\n    InputDevice leftController;\n    InputDevice rightController;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Initialize XR devices\n        var devices = new List<InputDevice>();\n        InputDevices.GetDevices(devices);\n\n        foreach (var device in devices)\n        {\n            if (device.role == InputDeviceRole.LeftHanded)\n                leftController = device;\n            else if (device.role == InputDeviceRole.RightHanded)\n                rightController = device;\n        }\n    }\n\n    void Update()\n    {\n        // Get controller inputs\n        if (leftController.isValid)\n        {\n            // Get trigger value\n            float triggerValue;\n            if (leftController.TryGetFeatureValue(CommonUsages.trigger, out triggerValue))\n            {\n                // Send command based on trigger\n                SendTeleoperationCommand(triggerValue);\n            }\n        }\n    }\n\n    void SendTeleoperationCommand(float value)\n    {\n        // Publish command to ROS\n        // ros.Publish(commandTopic, commandMsg);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsx)(e.h3,{id:"1-scene-organization",children:"1. Scene Organization"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Use meaningful names for GameObjects"}),"\n",(0,o.jsx)(e.li,{children:"Group related objects under parent GameObjects"}),"\n",(0,o.jsx)(e.li,{children:"Use tags and layers for efficient selection"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"2-resource-management",children:"2. Resource Management"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Use object pooling for frequently instantiated objects"}),"\n",(0,o.jsx)(e.li,{children:"Implement proper garbage collection"}),"\n",(0,o.jsx)(e.li,{children:"Optimize textures and 3D models for performance"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"3-network-communication",children:"3. Network Communication"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Implement proper error handling for ROS connections"}),"\n",(0,o.jsx)(e.li,{children:"Use appropriate update rates to avoid network congestion"}),"\n",(0,o.jsx)(e.li,{children:"Consider data compression for large messages"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"4-physics-settings",children:"4. Physics Settings"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Use appropriate physics settings for your application"}),"\n",(0,o.jsx)(e.li,{children:"Balance accuracy with performance requirements"}),"\n",(0,o.jsx)(e.li,{children:"Test with various scenarios to ensure stability"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"integration-workflow",children:"Integration Workflow"}),"\n",(0,o.jsx)(e.h3,{id:"development-pipeline",children:"Development Pipeline"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"[ROS 2 Nodes] \u2194 [ROS-TCP-Endpoint] \u2194 [Unity Scene] \u2194 [Visualization]\n"})}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Design Phase"}),": Create 3D models and scenes in Unity"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Integration Phase"}),": Connect Unity to ROS 2 using TCP connector"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Testing Phase"}),": Validate data flow and visualization accuracy"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Optimization Phase"}),": Improve performance and visual quality"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Deployment Phase"}),": Package for target platform"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,o.jsx)(e.h3,{id:"connection-problems",children:"Connection Problems"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Verify ROS connection\nvoid CheckConnection()\n{\n    if (ROSConnection.instance == null)\n    {\n        Debug.LogError("ROS Connection not initialized!");\n        return;\n    }\n\n    if (!ROSConnection.instance.IsConnected())\n    {\n        Debug.LogWarning("Not connected to ROS bridge");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Reduce polygon count of 3D models"}),"\n",(0,o.jsx)(e.li,{children:"Use texture atlasing to reduce draw calls"}),"\n",(0,o.jsx)(e.li,{children:"Implement frustum culling for distant objects"}),"\n",(0,o.jsx)(e.li,{children:"Optimize shader complexity"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Unity provides a powerful platform for robotics visualization and simulation, offering high-quality graphics, real-time performance, and extensive integration capabilities. When combined with ROS 2, Unity enables the creation of sophisticated digital twins, training environments, and visualization tools that bridge the gap between simulation and reality."}),"\n",(0,o.jsx)(e.p,{children:"The Unity Robotics ecosystem continues to evolve with new tools and capabilities, making it an increasingly attractive option for robotics researchers and developers who need high-fidelity visualization and simulation capabilities."}),"\n",(0,o.jsx)(e.p,{children:"In the next section, we'll create a practical lab exercise to apply these concepts."})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);