"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[1274],{6833:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module3/isaac-sim","title":"Isaac Sim for Advanced Simulation","description":"Introduction to Isaac Sim","source":"@site/docs/module3/isaac-sim.md","sourceDirName":"module3","slug":"/module3/isaac-sim","permalink":"/Physical-AI-Humanoid-book/docs/module3/isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/user/physical-ai-humanoid-robotics/tree/main/docs/module3/isaac-sim.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac SDK and Development Environment","permalink":"/Physical-AI-Humanoid-book/docs/module3/isaac-sdk"},"next":{"title":"Practical Lab: Building an AI-Powered Robot","permalink":"/Physical-AI-Humanoid-book/docs/module3/lab-ai-robot"}}');var t=r(4848),a=r(8453);const s={},o="Isaac Sim for Advanced Simulation",l={},c=[{value:"Introduction to Isaac Sim",id:"introduction-to-isaac-sim",level:2},{value:"Key Features of Isaac Sim",id:"key-features-of-isaac-sim",level:2},{value:"1. Photorealistic Rendering",id:"1-photorealistic-rendering",level:3},{value:"2. Accurate Physics Simulation",id:"2-accurate-physics-simulation",level:3},{value:"3. Synthetic Data Generation",id:"3-synthetic-data-generation",level:3},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:2},{value:"Installing and Setting Up Isaac Sim",id:"installing-and-setting-up-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Methods",id:"installation-methods",level:3},{value:"Method 1: Omniverse Launcher (Recommended)",id:"method-1-omniverse-launcher-recommended",level:4},{value:"Method 2: Docker Container",id:"method-2-docker-container",level:4},{value:"Isaac Sim Python API",id:"isaac-sim-python-api",level:2},{value:"Basic Scene Setup",id:"basic-scene-setup",level:3},{value:"Robot Control and Simulation",id:"robot-control-and-simulation",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:3},{value:"Advanced Simulation Features",id:"advanced-simulation-features",level:2},{value:"Physics Configuration",id:"physics-configuration",level:3},{value:"Dynamic Object Simulation",id:"dynamic-object-simulation",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Annotation Generation",id:"annotation-generation",level:3},{value:"Isaac Sim Extensions",id:"isaac-sim-extensions",level:2},{value:"Creating Custom Extensions",id:"creating-custom-extensions",level:3},{value:"Sensor Extensions",id:"sensor-extensions",level:3},{value:"Integration with AI/ML Frameworks",id:"integration-with-aiml-frameworks",level:2},{value:"PyTorch Integration",id:"pytorch-integration",level:3},{value:"TensorFlow Integration",id:"tensorflow-integration",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Multi-GPU Rendering",id:"multi-gpu-rendering",level:3},{value:"Physics Optimization",id:"physics-optimization",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"1. Rendering Issues",id:"1-rendering-issues",level:3},{value:"2. Physics Instability",id:"2-physics-instability",level:3},{value:"3. Memory Management",id:"3-memory-management",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Scene Optimization",id:"1-scene-optimization",level:3},{value:"2. Simulation Accuracy",id:"2-simulation-accuracy",level:3},{value:"3. Data Generation",id:"3-data-generation",level:3},{value:"Integration with Real Robots",id:"integration-with-real-robots",level:2},{value:"Sim-to-Real Transfer",id:"sim-to-real-transfer",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"isaac-sim-for-advanced-simulation",children:"Isaac Sim for Advanced Simulation"})}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-isaac-sim",children:"Introduction to Isaac Sim"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim is NVIDIA's high-fidelity simulation environment built on the Omniverse platform. It provides photorealistic rendering, accurate physics simulation, and synthetic data generation capabilities specifically designed for robotics development. Isaac Sim enables developers to create realistic digital twins, train AI models, and validate robotic systems before deploying them in the real world."}),"\n",(0,t.jsx)(e.h2,{id:"key-features-of-isaac-sim",children:"Key Features of Isaac Sim"}),"\n",(0,t.jsx)(e.h3,{id:"1-photorealistic-rendering",children:"1. Photorealistic Rendering"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim leverages NVIDIA's RTX technology for real-time ray tracing and physically-based rendering:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Global illumination"}),": Accurate light simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Realistic materials"}),": Physically-based material properties"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"High dynamic range"}),": Accurate lighting representation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-GPU rendering"}),": Scale rendering across multiple GPUs"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"2-accurate-physics-simulation",children:"2. Accurate Physics Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Built on NVIDIA PhysX 5.0, Isaac Sim provides:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-body dynamics"}),": Complex interactions between objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Soft body simulation"}),": Deformable object physics"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Fluid simulation"}),": Liquid and gas interactions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contact dynamics"}),": Accurate collision response"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"3-synthetic-data-generation",children:"3. Synthetic Data Generation"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim excels at generating training data for AI models:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Large-scale datasets"}),": Generate thousands of diverse scenarios"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Domain randomization"}),": Vary environmental parameters"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Automatic annotation"}),": Ground truth generation for training"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor simulation"}),": Realistic sensor data"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                   Omniverse Core                        \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\r\n\u2502  \u2502   USD       \u2502 \u2502   PhysX     \u2502 \u2502   RTX       \u2502       \u2502\r\n\u2502  \u2502   Scene     \u2502 \u2502   Physics   \u2502 \u2502   Rendering \u2502       \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                Isaac Sim Extensions                     \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\r\n\u2502  \u2502   Robotics  \u2502 \u2502   Sensors   \u2502 \u2502   AI/ML     \u2502       \u2502\r\n\u2502  \u2502   Framework \u2502 \u2502   Simulation\u2502 \u2502   Training  \u2502       \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                  User Interface                         \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\r\n\u2502  \u2502   Isaac Sim \u2502 \u2502   Omniverse \u2502 \u2502   Extension \u2502       \u2502\r\n\u2502  \u2502   App       \u2502 \u2502   Editor    \u2502 \u2502   APIs      \u2502       \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(e.h2,{id:"installing-and-setting-up-isaac-sim",children:"Installing and Setting Up Isaac Sim"}),"\n",(0,t.jsx)(e.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"OS"}),": Windows 10/11, Ubuntu 20.04 LTS"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"GPU"}),": NVIDIA RTX GPU with 8GB+ VRAM (RTX 3080+ recommended)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RAM"}),": 32GB+ system memory"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Storage"}),": 50GB+ free space"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"CUDA"}),": 11.8 or later"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-GPU"}),": Optional for enhanced performance"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"installation-methods",children:"Installation Methods"}),"\n",(0,t.jsx)(e.h4,{id:"method-1-omniverse-launcher-recommended",children:"Method 1: Omniverse Launcher (Recommended)"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Download Omniverse Launcher from NVIDIA Developer website\r\n# Install Isaac Sim extension through the launcher\r\n# Launch Isaac Sim from the extension manager\n"})}),"\n",(0,t.jsx)(e.h4,{id:"method-2-docker-container",children:"Method 2: Docker Container"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Pull Isaac Sim Docker image\r\ndocker pull nvcr.io/nvidia/isaac-sim:4.0.0\r\n\r\n# Run Isaac Sim container\r\ndocker run --gpus all -it \\\r\n  --name isaac-sim \\\r\n  --net=host \\\r\n  --mount "type=bind,src=/tmp/.X11-unix,dst=/tmp/.X11-unix" \\\r\n  --mount "type=bind,src=/home/$USER,dst=/home/$USER" \\\r\n  --mount "type=bind,src=/var/run/dbus/system_bus_socket,dst=/var/run/dbus/system_bus_socket" \\\r\n  --env="DISPLAY" \\\r\n  --privileged \\\r\n  --pid=host \\\r\n  nvcr.io/nvidia/isaac-sim:4.0.0\n'})}),"\n",(0,t.jsx)(e.h2,{id:"isaac-sim-python-api",children:"Isaac Sim Python API"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim provides a comprehensive Python API for programmatic control:"}),"\n",(0,t.jsx)(e.h3,{id:"basic-scene-setup",children:"Basic Scene Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Import Isaac Sim modules\r\nfrom omni.isaac.kit import SimulationApp\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\nfrom pxr import Gf, UsdGeom\r\n\r\n# Start the simulation application\r\nconfig = {\r\n    "headless": False,\r\n    "rendering_fps": 60,\r\n    "simulation_frequency": 60.0\r\n}\r\nsimulation_app = SimulationApp(config)\r\n\r\n# Create world instance\r\nworld = World(stage_units_in_meters=1.0)\r\n\r\n# Add a ground plane\r\nworld.scene.add_default_ground_plane()\r\n\r\n# Load a robot model\r\nadd_reference_to_stage(\r\n    usd_path="/path/to/robot_model.usd",\r\n    prim_path="/World/Robot"\r\n)\r\n\r\n# Reset the world\r\nworld.reset()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"robot-control-and-simulation",children:"Robot Control and Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\n\r\n# Add a robot to the scene\r\nrobot = world.scene.add(\r\n    Robot(\r\n        prim_path="/World/Robot",\r\n        name="my_robot",\r\n        usd_path=get_assets_root_path() + "/Isaac/Robots/Franka/franka_instanceable.usd"\r\n    )\r\n)\r\n\r\n# Control the robot\r\nfor i in range(1000):\r\n    # Get current joint positions\r\n    joint_positions = robot.get_joint_positions()\r\n\r\n    # Apply joint commands (example: simple sine wave motion)\r\n    joint_commands = np.sin(i * 0.01) * 0.5\r\n    robot.apply_action(joint_commands)\r\n\r\n    # Step the simulation\r\n    world.step(render=True)\r\n\r\n    # Print robot state periodically\r\n    if i % 100 == 0:\r\n        print(f"Step {i}, Joint positions: {joint_positions}")\n'})}),"\n",(0,t.jsx)(e.h3,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\r\nfrom omni.isaac.core.utils.prims import define_prim\r\nimport carb\r\n\r\n# Add a camera sensor to the robot\r\ncamera = world.scene.add(\r\n    Camera(\r\n        prim_path="/World/Robot/Camera",\r\n        name="robot_camera",\r\n        translation=np.array([0.2, 0, 0.1]),\r\n        orientation=np.array([0, 0, 0, 1])\r\n    )\r\n)\r\n\r\n# Set camera properties\r\ncamera.set_focal_length(24.0)\r\ncamera.set_horizontal_aperture(20.955)\r\ncamera.set_vertical_aperture(15.29)\r\n\r\n# Capture images\r\nfor i in range(100):\r\n    world.step(render=True)\r\n\r\n    # Get RGB image\r\n    rgb_data = camera.get_rgb()\r\n\r\n    # Get depth data\r\n    depth_data = camera.get_depth()\r\n\r\n    # Get segmentation data\r\n    seg_data = camera.get_semantic_segmentation()\r\n\r\n    print(f"Captured image {i}, RGB shape: {rgb_data.shape}")\n'})}),"\n",(0,t.jsx)(e.h2,{id:"advanced-simulation-features",children:"Advanced Simulation Features"}),"\n",(0,t.jsx)(e.h3,{id:"physics-configuration",children:"Physics Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from omni.physx.scripts import physicsUtils\r\nfrom pxr import PhysxSchema\r\n\r\n# Configure physics properties\r\ndef setup_physics_properties(stage):\r\n    # Set gravity\r\n    physicsUtils.set_physics_scene_up_axis(stage, "Y")\r\n    physicsUtils.set_physics_scene_gravity(stage, Gf.Vec3f(0, -9.81, 0))\r\n\r\n    # Configure default physics material\r\n    material_path = "/World/PhysicsMaterial"\r\n    physicsUtils.add_material_to_stage(stage, material_path)\r\n\r\n    # Set material properties\r\n    material = PhysxSchema.PhysxMaterialDefAPI.Apply(stage.GetPrimAtPath(material_path))\r\n    material.GetStaticFrictionAttr().Set(0.5)\r\n    material.GetDynamicFrictionAttr().Set(0.4)\r\n    material.GetRestitutionAttr().Set(0.1)\r\n\r\n# Apply physics configuration\r\nstage = world.stage\r\nsetup_physics_properties(stage)\n'})}),"\n",(0,t.jsx)(e.h3,{id:"dynamic-object-simulation",children:"Dynamic Object Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from omni.isaac.core.objects import DynamicCuboid\r\nfrom omni.isaac.core.prims import RigidPrim\r\nimport numpy as np\r\n\r\n# Add dynamic objects to the scene\r\ndef add_dynamic_objects():\r\n    # Add a stack of cubes\r\n    for i in range(5):\r\n        cube = world.scene.add(\r\n            DynamicCuboid(\r\n                prim_path=f"/World/Cube_{i}",\r\n                name=f"cube_{i}",\r\n                position=np.array([0.5, 1.0 + i * 0.25, 0.5]),\r\n                size=0.2,\r\n                color=np.array([0.8, 0.1, 0.1])\r\n            )\r\n        )\r\n\r\n    # Add a sphere\r\n    sphere = world.scene.add(\r\n        DynamicCuboid(  # Using DynamicCuboid with spherical shape\r\n            prim_path="/World/Sphere",\r\n            name="sphere",\r\n            position=np.array([0.8, 1.0, 0.8]),\r\n            size=0.15,\r\n            color=np.array([0.1, 0.8, 0.1])\r\n        )\r\n    )\r\n\r\nadd_dynamic_objects()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,t.jsx)(e.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import random\r\nfrom omni.isaac.core.materials import VisualMaterial\r\nfrom pxr import Gf\r\n\r\nclass DomainRandomizer:\r\n    def __init__(self, world):\r\n        self.world = world\r\n        self.stage = world.stage\r\n\r\n    def randomize_lighting(self):\r\n        """Randomize lighting conditions in the scene"""\r\n        # Get the default light\r\n        light_prim = self.stage.GetPrimAtPath("/World/Light")\r\n\r\n        if light_prim.IsValid():\r\n            # Randomize light intensity\r\n            intensity = random.uniform(500, 1500)\r\n            light_prim.GetAttribute("intensity").Set(intensity)\r\n\r\n            # Randomize light color temperature\r\n            temperature = random.uniform(5000, 7000)\r\n            light_prim.GetAttribute("colorTemperature").Set(temperature)\r\n\r\n    def randomize_materials(self):\r\n        """Randomize material properties"""\r\n        # Get all materials in the scene\r\n        material_prims = [prim for prim in self.stage.TraverseAll()\r\n                         if prim.GetTypeName() == "Material"]\r\n\r\n        for prim in material_prims:\r\n            # Randomize roughness\r\n            roughness = random.uniform(0.1, 0.9)\r\n            # Apply roughness randomization\r\n\r\n            # Randomize metallic\r\n            metallic = random.uniform(0.0, 1.0)\r\n            # Apply metallic randomization\r\n\r\n    def randomize_background(self):\r\n        """Randomize background environment"""\r\n        # Change background texture or color\r\n        background_options = [\r\n            "indoor_office",\r\n            "outdoor_garden",\r\n            "indoor_warehouse",\r\n            "outdoor_street"\r\n        ]\r\n        selected_background = random.choice(background_options)\r\n        # Apply selected background\r\n\r\n# Usage\r\nrandomizer = DomainRandomizer(world)\r\n\r\nfor episode in range(1000):\r\n    # Randomize environment\r\n    randomizer.randomize_lighting()\r\n    randomizer.randomize_materials()\r\n    randomizer.randomize_background()\r\n\r\n    # Run simulation episode\r\n    for step in range(100):\r\n        world.step(render=True)\r\n\r\n        # Capture data\r\n        image = camera.get_rgb()\r\n        depth = camera.get_depth()\r\n\r\n        # Save data with annotations\r\n        save_training_data(image, depth, f"episode_{episode}_step_{step}")\n'})}),"\n",(0,t.jsx)(e.h3,{id:"annotation-generation",children:"Annotation Generation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def generate_annotations():\r\n    \"\"\"Generate ground truth annotations for synthetic data\"\"\"\r\n\r\n    # Get segmentation data\r\n    seg_data = camera.get_semantic_segmentation()\r\n\r\n    # Get bounding boxes for objects\r\n    bboxes = []\r\n    for obj in world.scene.objects:\r\n        bbox = get_bounding_box_2d(obj, camera)\r\n        bboxes.append({\r\n            'object_id': obj.name,\r\n            'bbox': bbox,\r\n            'class': get_object_class(obj)\r\n        })\r\n\r\n    # Generate depth annotations\r\n    depth_data = camera.get_depth()\r\n\r\n    # Generate pose annotations\r\n    poses = []\r\n    for obj in world.scene.objects:\r\n        pose = obj.get_world_pose()\r\n        poses.append({\r\n            'object_id': obj.name,\r\n            'position': pose[0],\r\n            'orientation': pose[1]\r\n        })\r\n\r\n    return {\r\n        'segmentation': seg_data,\r\n        'bounding_boxes': bboxes,\r\n        'depth': depth_data,\r\n        'poses': poses\r\n    }\r\n\r\ndef save_training_data(image, annotations, filename):\r\n    \"\"\"Save image and annotations for training\"\"\"\r\n    import cv2\r\n    import json\r\n\r\n    # Save RGB image\r\n    cv2.imwrite(f\"images/{filename}.png\", cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\r\n\r\n    # Save annotations\r\n    with open(f\"annotations/{filename}.json\", 'w') as f:\r\n        json.dump(annotations, f)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"isaac-sim-extensions",children:"Isaac Sim Extensions"}),"\n",(0,t.jsx)(e.h3,{id:"creating-custom-extensions",children:"Creating Custom Extensions"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Example custom extension for Isaac Sim\r\nimport omni.ext\r\nimport omni.ui as ui\r\nfrom omni.isaac.core import World\r\n\r\nclass CustomRobotExtension(omni.ext.IExt):\r\n    def on_startup(self, ext_id):\r\n        print("[my_robot_extension] Startup")\r\n\r\n        # Create UI window\r\n        self._window = ui.Window("Robot Controller", width=300, height=300)\r\n\r\n        with self._window.frame:\r\n            with ui.VStack():\r\n                ui.Label("Robot Control Panel")\r\n\r\n                # Add control buttons\r\n                self._reset_button = ui.Button("Reset Simulation")\r\n                self._reset_button.set_clicked_fn(self._on_reset_clicked)\r\n\r\n                self._start_button = ui.Button("Start Robot")\r\n                self._start_button.set_clicked_fn(self._on_start_clicked)\r\n\r\n    def _on_reset_clicked(self):\r\n        """Reset the simulation"""\r\n        world = World.instance()\r\n        if world:\r\n            world.reset()\r\n\r\n    def _on_start_clicked(self):\r\n        """Start robot control"""\r\n        print("Starting robot control...")\r\n        # Add robot control logic here\r\n\r\n    def on_shutdown(self):\r\n        print("[my_robot_extension] Shutdown")\n'})}),"\n",(0,t.jsx)(e.h3,{id:"sensor-extensions",children:"Sensor Extensions"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from omni.isaac.core.sensors import Sensor\r\nfrom omni.isaac.core.prims import XFormPrim\r\nimport numpy as np\r\n\r\nclass CustomLidar(Sensor):\r\n    def __init__(self, prim_path, name, translation=np.array([0, 0, 0]),\r\n                 orientation=np.array([0, 0, 0, 1]), frequency=10):\r\n        super().__init__(prim_path=prim_path, name=name,\r\n                        translation=translation, orientation=orientation)\r\n        self._frequency = frequency\r\n        self._scan_data = None\r\n\r\n    def initialize(self):\r\n        super().initialize()\r\n        # Initialize custom lidar parameters\r\n        self._horizontal_samples = 720\r\n        self._vertical_samples = 1\r\n        self._min_range = 0.1\r\n        self._max_range = 30.0\r\n\r\n    def get_current_frame(self):\r\n        """Get current lidar scan data"""\r\n        # Perform raycasting to simulate lidar\r\n        scan_data = self._simulate_lidar_scan()\r\n        self._scan_data = scan_data\r\n        return scan_data\r\n\r\n    def _simulate_lidar_scan(self):\r\n        """Simulate lidar raycasting"""\r\n        ranges = []\r\n\r\n        # Simulate horizontal scan\r\n        for i in range(self._horizontal_samples):\r\n            angle = (i / self._horizontal_samples) * 2 * np.pi\r\n\r\n            # Raycast in the direction\r\n            direction = np.array([\r\n                np.cos(angle),\r\n                np.sin(angle),\r\n                0\r\n            ])\r\n\r\n            # Perform collision detection (simplified)\r\n            distance = self._raycast_distance(direction)\r\n            ranges.append(min(distance, self._max_range))\r\n\r\n        return np.array(ranges)\r\n\r\n    def _raycast_distance(self, direction):\r\n        """Simulate raycast distance measurement"""\r\n        # Simplified raycast implementation\r\n        # In real implementation, use Isaac Sim\'s physics scene\r\n        return self._max_range  # Placeholder\n'})}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-aiml-frameworks",children:"Integration with AI/ML Frameworks"}),"\n",(0,t.jsx)(e.h3,{id:"pytorch-integration",children:"PyTorch Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\r\nimport numpy as np\r\nfrom omni.isaac.core import World\r\n\r\nclass IsaacSimEnvironment:\r\n    def __init__(self):\r\n        self.world = World.instance()\r\n        self.camera = None  # Initialize camera\r\n        self.robot = None   # Initialize robot\r\n\r\n    def get_observation(self):\r\n        """Get observation from simulation for RL training"""\r\n        # Get camera image\r\n        rgb_image = self.camera.get_rgb()\r\n\r\n        # Convert to PyTorch tensor\r\n        obs_tensor = torch.from_numpy(rgb_image).float()\r\n        obs_tensor = obs_tensor.permute(2, 0, 1)  # HWC to CHW\r\n        obs_tensor = obs_tensor / 255.0  # Normalize to [0,1]\r\n\r\n        # Get robot state\r\n        joint_positions = torch.from_numpy(\r\n            self.robot.get_joint_positions()\r\n        ).float()\r\n\r\n        # Combine observations\r\n        observation = {\r\n            \'image\': obs_tensor,\r\n            \'joint_positions\': joint_positions\r\n        }\r\n\r\n        return observation\r\n\r\n    def apply_action(self, action):\r\n        """Apply action to robot in simulation"""\r\n        # Convert action to robot commands\r\n        joint_commands = action.numpy() if torch.is_tensor(action) else action\r\n\r\n        # Apply commands to robot\r\n        self.robot.apply_action(joint_commands)\r\n\r\n    def get_reward(self):\r\n        """Calculate reward for current state"""\r\n        # Implement reward calculation logic\r\n        reward = 0.0\r\n        # Add reward calculation based on task\r\n        return reward\r\n\r\n    def reset(self):\r\n        """Reset the simulation environment"""\r\n        self.world.reset()\r\n        # Reset robot to initial position\r\n        # Reset objects to initial positions\n'})}),"\n",(0,t.jsx)(e.h3,{id:"tensorflow-integration",children:"TensorFlow Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import tensorflow as tf\r\nimport numpy as np\r\n\r\nclass TFIsaacSimAgent:\r\n    def __init__(self, model_path):\r\n        # Load TensorFlow model\r\n        self.model = tf.saved_model.load(model_path)\r\n\r\n    def predict_action(self, observation):\r\n        """Predict action using TensorFlow model"""\r\n        # Convert observation to TensorFlow tensor\r\n        obs_tensor = tf.convert_to_tensor(observation, dtype=tf.float32)\r\n        obs_tensor = tf.expand_dims(obs_tensor, axis=0)  # Add batch dimension\r\n\r\n        # Run inference\r\n        action = self.model(obs_tensor)\r\n\r\n        # Convert to numpy for Isaac Sim\r\n        return action.numpy()[0]  # Remove batch dimension\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"multi-gpu-rendering",children:"Multi-GPU Rendering"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def setup_multi_gpu_rendering():\r\n    """Configure multi-GPU rendering in Isaac Sim"""\r\n\r\n    # Enable multi-GPU rendering\r\n    carb.settings.get_settings().set_bool("/renderer/multi_gpu/enabled", True)\r\n\r\n    # Set GPU affinity\r\n    carb.settings.get_settings().set_int("/renderer/multi_gpu/primary_gpu", 0)\r\n    carb.settings.get_settings().set_int("/renderer/multi_gpu/secondary_gpu", 1)\r\n\r\n    # Configure render quality\r\n    carb.settings.get_settings().set_int("/renderer/quality", 3)  # High quality\r\n    carb.settings.get_settings().set_int("/renderer/resolution/width", 1920)\r\n    carb.settings.get_settings().set_int("/renderer/resolution/height", 1080)\n'})}),"\n",(0,t.jsx)(e.h3,{id:"physics-optimization",children:"Physics Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def optimize_physics_settings():\r\n    """Optimize physics settings for performance"""\r\n\r\n    # Set physics substeps for stability\r\n    carb.settings.get_settings().set_int("/physicsSolver/substeps", 4)\r\n\r\n    # Configure collision filtering\r\n    carb.settings.get_settings().set_int("/physicsScene/collisionUpdateCount", 1000)\r\n\r\n    # Set broadphase settings\r\n    carb.settings.get_settings().set_int("/physicsScene/broadphaseType", 1)  # Multi-SAP\n'})}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(e.h3,{id:"1-rendering-issues",children:"1. Rendering Issues"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Check rendering status\r\ndef check_rendering_status():\r\n    renderer = omni.kit.app.get_app().get_renderer()\r\n    if not renderer:\r\n        print("Renderer not initialized")\r\n        return False\r\n    return True\r\n\r\n# Reset rendering context\r\ndef reset_rendering():\r\n    carb.settings.get_settings().set_int("/app/window/scale", 1)\r\n    # Recreate rendering context if needed\n'})}),"\n",(0,t.jsx)(e.h3,{id:"2-physics-instability",children:"2. Physics Instability"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# Physics debugging\r\ndef debug_physics():\r\n    # Check for penetrating objects\r\n    # Verify mass and inertia properties\r\n    # Check joint limits and constraints\r\n    pass\n"})}),"\n",(0,t.jsx)(e.h3,{id:"3-memory-management",children:"3. Memory Management"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Monitor memory usage\r\ndef monitor_memory():\r\n    import psutil\r\n    memory_percent = psutil.virtual_memory().percent\r\n    print(f"System memory usage: {memory_percent}%")\r\n\r\n    # Clear unused assets if needed\r\n    omni.kit.commands.execute("DeletePrims", paths=["/World/UnusedObject"])\n'})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(e.h3,{id:"1-scene-optimization",children:"1. Scene Optimization"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use simplified collision meshes"}),"\n",(0,t.jsx)(e.li,{children:"Implement level-of-detail (LOD) for complex objects"}),"\n",(0,t.jsx)(e.li,{children:"Use instancing for repeated objects"}),"\n",(0,t.jsx)(e.li,{children:"Optimize texture resolution"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"2-simulation-accuracy",children:"2. Simulation Accuracy"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Validate physics parameters against real-world data"}),"\n",(0,t.jsx)(e.li,{children:"Use appropriate time steps for stability"}),"\n",(0,t.jsx)(e.li,{children:"Implement proper sensor noise models"}),"\n",(0,t.jsx)(e.li,{children:"Include environmental variations"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"3-data-generation",children:"3. Data Generation"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implement comprehensive domain randomization"}),"\n",(0,t.jsx)(e.li,{children:"Generate diverse training scenarios"}),"\n",(0,t.jsx)(e.li,{children:"Include edge cases and failure modes"}),"\n",(0,t.jsx)(e.li,{children:"Validate synthetic data quality"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-real-robots",children:"Integration with Real Robots"}),"\n",(0,t.jsx)(e.h3,{id:"sim-to-real-transfer",children:"Sim-to-Real Transfer"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def prepare_for_real_world():\r\n    """Prepare simulation for sim-to-real transfer"""\r\n\r\n    # Add sensor noise to match real sensors\r\n    add_sensor_noise_models()\r\n\r\n    # Include actuator dynamics\r\n    model_actuator_delays()\r\n\r\n    # Add environmental uncertainties\r\n    introduce_uncertainty_factors()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim provides a powerful platform for high-fidelity robotics simulation with photorealistic rendering, accurate physics, and synthetic data generation capabilities. Its integration with the broader Isaac ecosystem and support for AI/ML frameworks makes it an ideal environment for developing and training AI-powered robotic systems."}),"\n",(0,t.jsx)(e.p,{children:"The platform's extensibility through Python APIs and custom extensions allows for tailored simulation environments that match specific robotics applications. Understanding Isaac Sim's capabilities and best practices is essential for leveraging simulation effectively in robotics development workflows."}),"\n",(0,t.jsx)(e.p,{children:"In the next section, we'll explore AI perception systems using Isaac's tools and frameworks."})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>s,x:()=>o});var i=r(6540);const t={},a=i.createContext(t);function s(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);